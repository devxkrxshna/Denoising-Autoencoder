{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devxkrxshna/Denoising-Autoencoder/blob/main/denoisingAutoencoderPhaseII.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC2u3f9Hco4C",
        "outputId": "c9e8fa81-c4d7-419f-e123-c4073645544f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "N23MfN7DSB6F"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import sys \n",
        "import math \n",
        "#import timm \n",
        "\n",
        "import numpy as np \n",
        "\n",
        "\n",
        "import torch \n",
        "import torch.nn as  nn \n",
        "\n",
        "def preprocess_input(x, mean=None, std=None, input_space=\"RGB\", input_range=None, **kwargs):\n",
        "\n",
        "    if input_space == \"BGR\":\n",
        "        x = x[..., ::-1].copy() \n",
        "    \n",
        "    if input_range is not None:\n",
        "        if x.max() > 1 and input_range[1] == 1:\n",
        "            x = x / 255.0 \n",
        "    \n",
        "    if mean is not None:\n",
        "        mean = np.array(mean)\n",
        "        x = x - mean \n",
        "\n",
        "    if std is not None:\n",
        "        std = np.array(std)\n",
        "        x = x / std \n",
        "    \n",
        "    return x\n",
        "\n",
        "\n",
        "def patch_first_conv(model, new_in_channels, default_in_channels=3, pretrained=True):\n",
        "\n",
        "    for module in model.modules():\n",
        "        if isinstance(module, nn.Conv2d) and module.in_channels == default_in_channels:\n",
        "            break \n",
        "            \n",
        "    weight = module.weight.detach()\n",
        "    module.in_channels = new_in_channels \n",
        "\n",
        "    if not pretrained:\n",
        "        module.weight = nn.parameter.Parameter( torch.Tensor(module.out_channels, \n",
        "                         new_in_channels // module.groups, *module.kernel_size))\n",
        "        module.reset_parameters() \n",
        "    \n",
        "    elif new_in_channels == 1:\n",
        "        new_weight = weight.sum(1, keepdim=True)\n",
        "        module.weight = nn.parameter.Parameter(new_weight) \n",
        "    \n",
        "    else:\n",
        "        new_weight = torch.Tensor(module.out_channels, new_in_channels // module.groups, *module.kernel_size) \n",
        "\n",
        "        for i in range(new_in_channels):\n",
        "            new_weight[:, i] = weight[:, i % default_in_channels]\n",
        "\n",
        "        new_weight = new_weight * (default_in_channels / new_in_channels)\n",
        "        module.weight = nn.parameter.Parameter(new_weight) \n",
        "\n",
        "\n",
        "def replace_strides_with_dilation(module, dilation_rate):\n",
        "\n",
        "    for mod in module.modules():\n",
        "        if isinstance(mod, nn.Conv2d):\n",
        "            mod.stride = (1, 1)\n",
        "            mod.dilation = (dilation_rate, dilation_rate)\n",
        "            kh, kw = mod.kernel_size\n",
        "            mod.padding = ((kh // 2) * dilation_rate, (kh // 2) * dilation_rate) \n",
        "            \n",
        "            if hasattr(mod, \"static_padding\"):\n",
        "                mod.static_padding = nn.Identity() \n",
        "\n",
        "\n",
        "class EncoderMixin:\n",
        "\n",
        "    _output_stride = 32\n",
        "\n",
        "\n",
        "    @property \n",
        "    def out_channels(self):\n",
        "        return self._out_channels[: self._depth + 1] \n",
        "    \n",
        "    @property \n",
        "    def output_stride(self):\n",
        "        return min(self._output_stride, 2 ** self._depth) \n",
        "    \n",
        "    def set_in_channels(self, in_channels, pretrained=True): \n",
        "        if in_channels == 3:\n",
        "            return \n",
        "    \n",
        "        self._in_channels = in_channels\n",
        "        if self._out_channels[0] == 3: \n",
        "            self._out_channels = tuple([in_channels] + list(self._out_channels)[1:]) \n",
        "        \n",
        "        patch_first_conv(model=self, new_in_channels=in_channels, pretrained=pretrained) \n",
        "    \n",
        "    def get_stages(self):\n",
        "        raise NotImplementedError \n",
        "    \n",
        "    def make_dilated(self, output_stride):\n",
        "\n",
        "        if output_stride == 16:\n",
        "            stage_list = [\n",
        "                5,\n",
        "            ]\n",
        "            dilation_list = [\n",
        "                2,\n",
        "            ]\n",
        "\n",
        "        elif output_stride == 8:\n",
        "            stage_list = [4, 5]\n",
        "            dilation_list = [2, 4]\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Output stride should be 16 or 8, got {}.\".format(output_stride))\n",
        "\n",
        "        self._output_stride = output_stride\n",
        "\n",
        "        stages = self.get_stages()\n",
        "        for stage_indx, dilation_rate in zip(stage_list, dilation_list):\n",
        "            replace_strides_with_dilation(\n",
        "                module=stages[stage_indx],\n",
        "                dilation_rate=dilation_rate,) \n",
        "\n",
        "\n",
        "class TimmUniversalEncoder(nn.Module):\n",
        "    def __init__(self, name, pretrained=True, in_channels=3, depth=5, output_stride=32): \n",
        "        super().__init__() \n",
        "        kwargs = dict( in_chans=in_channels,   features_only=True,  output_stride=output_stride,\n",
        "            pretrained=pretrained,   out_indices=tuple(range(depth)), ) \n",
        "        \n",
        "        if output_stride == 32:\n",
        "            kwargs.pop(\"output_stride\") \n",
        "        \n",
        "        self.model = timm.create_model(name, **kwargs)\n",
        "        self._in_channels = in_channels \n",
        "        self._out_channels = [in_channels,] + self.model.feature_info.channels()\n",
        "        self._depth = depth\n",
        "        self._output_stride = output_stride\n",
        "    \n",
        "    def forward(self, x):\n",
        "        features = self.model(x)\n",
        "        features = [ x, ] + features\n",
        "        return features \n",
        "    \n",
        "    @property \n",
        "    def out_channels(self): \n",
        "        return self._out_channels \n",
        "    \n",
        "    @property \n",
        "    def output_stride(self):\n",
        "        return min(self._output_stride, 2 ** self._depth) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whspgSTtbPxr",
        "outputId": "eb3675a0-8590-4f7d-b3f1-6bbd014bc00e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting timm\n",
            "  Downloading timm-0.9.1-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m29.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.15.1+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0)\n",
            "Collecting huggingface-hub (from timm)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from timm)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.7->timm) (16.0.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2023.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, timm\n",
            "Successfully installed huggingface-hub-0.14.1 safetensors-0.3.1 timm-0.9.1\n"
          ]
        }
      ],
      "source": [
        "pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "vW4YTL9LSUgN"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import sys \n",
        "import math \n",
        "\n",
        "import numpy as np \n",
        "\n",
        "import torch \n",
        "import torch.nn as  nn \n",
        "\n",
        "\n",
        "#from .utils import EncoderMixin \n",
        "from timm.models.resnet import ResNet \n",
        "from timm.models.resnet import Bottleneck \n",
        "\n",
        "\n",
        "\n",
        "class ResNestEncoder(ResNet, EncoderMixin):\n",
        "    def __init__(self, out_channels, depth=5, **kwargs):\n",
        "        super().__init__(**kwargs) \n",
        "        self._depth = depth\n",
        "        self._out_channels = out_channels\n",
        "        self._in_channels = 3 \n",
        "    \n",
        "        del self.fc \n",
        "        del self.global_pool \n",
        "    \n",
        "    def get_stages(self):\n",
        "\n",
        "        return [ \n",
        "            nn.Identity(), nn.Sequential(self.conv1, self.bn1, self.act1), \n",
        "            nn.Sequential(self.maxpool, self.layer1), self.layer2, self.layer3, self.layer4 \n",
        "        ]\n",
        "\n",
        "    def make_dilated(self, *args, **kwargs):\n",
        "        raise ValueError(\"ResNest encoders do not support dilated mode\") \n",
        "    \n",
        "    def forward(self, x): \n",
        "        stages = self.get_stages() \n",
        "        features = [ ] \n",
        "\n",
        "        for i in range(self._depth + 1):\n",
        "            x = stages[i](x) \n",
        "            features.append(x) \n",
        "        return features \n",
        "\n",
        "    def load_state_dict(self, state_dict, **kwargs):\n",
        "        state_dict.pop(\"fc.bias\", None)\n",
        "        state_dict.pop(\"fc.weight\", None)\n",
        "        super().load_state_dict(state_dict, **kwargs) \n",
        "    \n",
        "\n",
        "resnest_weights = {\n",
        "    \"timm-resnest14d\": {\n",
        "        \"imagenet\": \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gluon_resnest14-9c8fe254.pth\",  # noqa\n",
        "    },\n",
        "    \"timm-resnest26d\": {\n",
        "        \"imagenet\": \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/gluon_resnest26-50eb607c.pth\",  # noqa\n",
        "    },\n",
        "    \"timm-resnest50d\": {\n",
        "        \"imagenet\": \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest50-528c19ca.pth\",  # noqa\n",
        "    },\n",
        "    \"timm-resnest101e\": {\n",
        "        \"imagenet\": \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest101-22405ba7.pth\",  # noqa\n",
        "    },\n",
        "    \"timm-resnest200e\": {\n",
        "        \"imagenet\": \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest200-75117900.pth\",  # noqa\n",
        "    },\n",
        "    \"timm-resnest269e\": {\n",
        "        \"imagenet\": \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest269-0cc87c48.pth\",  # noqa\n",
        "    },\n",
        "    \"timm-resnest50d_4s2x40d\": {\n",
        "        \"imagenet\": \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest50_fast_4s2x40d-41d14ed0.pth\",  # noqa\n",
        "    },\n",
        "    \"timm-resnest50d_1s4x24d\": {\n",
        "        \"imagenet\": \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-resnest/resnest50_fast_1s4x24d-d4a4f76f.pth\",  # noqa\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "pretrained_settings = {}\n",
        "for model_name, sources in resnest_weights.items():\n",
        "    pretrained_settings[model_name] = {}\n",
        "    for source_name, source_url in sources.items():\n",
        "        pretrained_settings[model_name][source_name] = {\n",
        "            \"url\": source_url,\n",
        "            \"input_size\": [3, 224, 224],\n",
        "            \"input_range\": [0, 1],\n",
        "            \"mean\": [0.485, 0.456, 0.406],\n",
        "            \"std\": [0.229, 0.224, 0.225],\n",
        "            \"num_classes\": 1000,\n",
        "        }\n",
        "\n",
        "\n",
        "timm_resnest_encoders = {\n",
        "    \"timm-resnest14d\": {\n",
        "        \"encoder\": ResNestEncoder,\n",
        "        \"pretrained_settings\": pretrained_settings[\"timm-resnest14d\"],\n",
        "        \"params\": {\n",
        "            \"out_channels\": (3, 64, 256, 512, 1024, 2048),\n",
        "            \"block\": Bottleneck,\n",
        "            \"layers\": [1, 1, 1, 1],\n",
        "            \"stem_type\": \"deep\",\n",
        "            \"stem_width\": 32,\n",
        "            \"avg_down\": True,\n",
        "            \"base_width\": 64,\n",
        "            \"cardinality\": 1,\n",
        "            \"block_args\": {\"radix\": 2, \"avd\": True, \"avd_first\": False},\n",
        "        },\n",
        "    },\n",
        "\n",
        "    \"timm-resnest26d\": {\n",
        "        \"encoder\": ResNestEncoder,\n",
        "        \"pretrained_settings\": pretrained_settings[\"timm-resnest26d\"],\n",
        "        \"params\": {\n",
        "            \"out_channels\": (3, 64, 256, 512, 1024, 2048),\n",
        "            \"block\": Bottleneck,\n",
        "            \"layers\": [2, 2, 2, 2],\n",
        "            \"stem_type\": \"deep\",\n",
        "            \"stem_width\": 32,\n",
        "            \"avg_down\": True,\n",
        "            \"base_width\": 64,\n",
        "            \"cardinality\": 1,\n",
        "            \"block_args\": {\"radix\": 2, \"avd\": True, \"avd_first\": False},\n",
        "        },\n",
        "    },\n",
        "\n",
        "    \"timm-resnest50d\": {\n",
        "        \"encoder\": ResNestEncoder,\n",
        "        \"pretrained_settings\": pretrained_settings[\"timm-resnest50d\"],\n",
        "        \"params\": {\n",
        "            \"out_channels\": (3, 64, 256, 512, 1024, 2048),\n",
        "            \"block\": Bottleneck,\n",
        "            \"layers\": [3, 4, 6, 3],\n",
        "            \"stem_type\": \"deep\",\n",
        "            \"stem_width\": 32,\n",
        "            \"avg_down\": True,\n",
        "            \"base_width\": 64,\n",
        "            \"cardinality\": 1,\n",
        "            \"block_args\": {\"radix\": 2, \"avd\": True, \"avd_first\": False},\n",
        "        },\n",
        "    },\n",
        "\n",
        "    \"timm-resnest101e\": {\n",
        "        \"encoder\": ResNestEncoder,\n",
        "        \"pretrained_settings\": pretrained_settings[\"timm-resnest101e\"],\n",
        "        \"params\": {\n",
        "            \"out_channels\": (3, 128, 256, 512, 1024, 2048),\n",
        "            \"block\": Bottleneck,\n",
        "            \"layers\": [3, 4, 23, 3],\n",
        "            \"stem_type\": \"deep\",\n",
        "            \"stem_width\": 64,\n",
        "            \"avg_down\": True,\n",
        "            \"base_width\": 64,\n",
        "            \"cardinality\": 1,\n",
        "            \"block_args\": {\"radix\": 2, \"avd\": True, \"avd_first\": False},\n",
        "        },\n",
        "    },\n",
        "\n",
        "     \"timm-resnest200e\": {\n",
        "        \"encoder\": ResNestEncoder,\n",
        "        \"pretrained_settings\": pretrained_settings[\"timm-resnest200e\"],\n",
        "        \"params\": {\n",
        "            \"out_channels\": (3, 128, 256, 512, 1024, 2048),\n",
        "            \"block\": Bottleneck,\n",
        "            \"layers\": [3, 24, 36, 3],\n",
        "            \"stem_type\": \"deep\",\n",
        "            \"stem_width\": 64,\n",
        "            \"avg_down\": True,\n",
        "            \"base_width\": 64,\n",
        "            \"cardinality\": 1,\n",
        "            \"block_args\": {\"radix\": 2, \"avd\": True, \"avd_first\": False},\n",
        "        },\n",
        "    },\n",
        "\n",
        "    \"timm-resnest269e\": {\n",
        "        \"encoder\": ResNestEncoder,\n",
        "        \"pretrained_settings\": pretrained_settings[\"timm-resnest269e\"],\n",
        "        \"params\": {\n",
        "            \"out_channels\": (3, 128, 256, 512, 1024, 2048),\n",
        "            \"block\": Bottleneck,\n",
        "            \"layers\": [3, 30, 48, 8],\n",
        "            \"stem_type\": \"deep\",\n",
        "            \"stem_width\": 64,\n",
        "            \"avg_down\": True,\n",
        "            \"base_width\": 64,\n",
        "            \"cardinality\": 1,\n",
        "            \"block_args\": {\"radix\": 2, \"avd\": True, \"avd_first\": False},\n",
        "        },\n",
        "    },\n",
        "\n",
        "    \"timm-resnest50d_4s2x40d\": {\n",
        "        \"encoder\": ResNestEncoder,\n",
        "        \"pretrained_settings\": pretrained_settings[\"timm-resnest50d_4s2x40d\"],\n",
        "        \"params\": {\n",
        "            \"out_channels\": (3, 64, 256, 512, 1024, 2048),\n",
        "            \"block\": Bottleneck,\n",
        "            \"layers\": [3, 4, 6, 3],\n",
        "            \"stem_type\": \"deep\",\n",
        "            \"stem_width\": 32,\n",
        "            \"avg_down\": True,\n",
        "            \"base_width\": 40,\n",
        "            \"cardinality\": 2,\n",
        "            \"block_args\": {\"radix\": 4, \"avd\": True, \"avd_first\": True},\n",
        "        },\n",
        "    },\n",
        "\n",
        "    \"timm-resnest50d_1s4x24d\": {\n",
        "        \"encoder\": ResNestEncoder,\n",
        "        \"pretrained_settings\": pretrained_settings[\"timm-resnest50d_1s4x24d\"],\n",
        "        \"params\": {\n",
        "            \"out_channels\": (3, 64, 256, 512, 1024, 2048),\n",
        "            \"block\": Bottleneck,\n",
        "            \"layers\": [3, 4, 6, 3],\n",
        "            \"stem_type\": \"deep\",\n",
        "            \"stem_width\": 32,\n",
        "            \"avg_down\": True,\n",
        "            \"base_width\": 24,\n",
        "            \"cardinality\": 4,\n",
        "            \"block_args\": {\"radix\": 1, \"avd\": True, \"avd_first\": True},\n",
        "        },\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3gQWFzM6SB0D"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import sys \n",
        "import math \n",
        "\n",
        "import numpy as np \n",
        "\n",
        "from copy import deepcopy \n",
        "\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "\n",
        "from torchvision.models.resnet import ResNet \n",
        "from torchvision.models.resnet import Bottleneck \n",
        "from torchvision.models.resnet import BasicBlock \n",
        "#from pretrainedmodels.models.torchvision_models import pretrained_settings  \n",
        "\n",
        "#from .utils import EncoderMixin\n",
        "\n",
        "\n",
        "class ResNetEncoder(ResNet, EncoderMixin):\n",
        "    def __init__(self, out_channels, depth=5, **kwargs):\n",
        "        super().__init__(**kwargs)  \n",
        "\n",
        "        self._depth = depth \n",
        "        self._out_channels = out_channels\n",
        "        self._in_channels = 3 \n",
        "\n",
        "        del self.fc \n",
        "        del self.avgpool \n",
        "    \n",
        "    def get_stages(self):\n",
        "        return [ \n",
        "            nn.Identity(), \n",
        "            nn.Sequential(self.conv1, self.bn1, self.relu),\n",
        "            nn.Sequential(self.maxpool, self.layer1),\n",
        "            self.layer2,\n",
        "            self.layer3,\n",
        "            self.layer4,\n",
        "        ]\n",
        "\n",
        "    def forward(self, x):\n",
        "        stages = self.get_stages() \n",
        "\n",
        "        features = [ ] \n",
        "        for i in range(self._depth + 1): \n",
        "            x = stages[i](x)\n",
        "            features.append(x) \n",
        "        return features \n",
        "    \n",
        "    def load_state_dict(self, state_dict, **kwargs): \n",
        "        state_dict.pop(\"fc.bias\", None) \n",
        "        state_dict.pop(\"fc.weight\", None)\n",
        "        super().load_state_dict(state_dict, **kwargs) \n",
        "\n",
        "\n",
        "\n",
        "new_settings = {\n",
        "    \"resnet18\": {\n",
        "        \"ssl\": \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnet18-d92f0530.pth\",  # noqa\n",
        "        \"swsl\": \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnet18-118f1556.pth\",  # noqa\n",
        "    },\n",
        "\n",
        "    \"resnet50\": {\n",
        "        \"ssl\": \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnet50-08389792.pth\",  # noqa\n",
        "        \"swsl\": \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnet50-16a12f1b.pth\",  # noqa\n",
        "    },\n",
        "\n",
        "     \"resnext50_32x4d\": {\n",
        "        \"imagenet\": \"https://download.pytorch.org/models/resnext50_32x4d-7cdf4587.pth\",\n",
        "        \"ssl\": \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnext50_32x4-ddb3e555.pth\",  # noqa\n",
        "        \"swsl\": \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnext50_32x4-72679e44.pth\",  # noqa\n",
        "    },\n",
        "    \"resnext101_32x4d\": {\n",
        "        \"ssl\": \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnext101_32x4-dc43570a.pth\",  # noqa\n",
        "        \"swsl\": \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnext101_32x4-3f87e46b.pth\",  # noqa\n",
        "    },\n",
        "    \"resnext101_32x8d\": {\n",
        "        \"imagenet\": \"https://download.pytorch.org/models/resnext101_32x8d-8ba56ff5.pth\",\n",
        "        \"instagram\": \"https://download.pytorch.org/models/ig_resnext101_32x8-c38310e5.pth\",\n",
        "        \"ssl\": \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnext101_32x8-2cfe2f8b.pth\",  # noqa\n",
        "        \"swsl\": \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnext101_32x8-b4712904.pth\",  # noqa\n",
        "    },\n",
        "    \"resnext101_32x16d\": {\n",
        "        \"instagram\": \"https://download.pytorch.org/models/ig_resnext101_32x16-c6f796b0.pth\",\n",
        "        \"ssl\": \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_supervised_resnext101_32x16-15fffa57.pth\",  # noqa\n",
        "        \"swsl\": \"https://dl.fbaipublicfiles.com/semiweaksupervision/model_files/semi_weakly_supervised_resnext101_32x16-f3559a9c.pth\",  # noqa\n",
        "    },\n",
        "    \"resnext101_32x32d\": {\n",
        "        \"instagram\": \"https://download.pytorch.org/models/ig_resnext101_32x32-e4b90b00.pth\",\n",
        "    },\n",
        "    \"resnext101_32x48d\": {\n",
        "        \"instagram\": \"https://download.pytorch.org/models/ig_resnext101_32x48-3e41cc8a.pth\",\n",
        "    },\n",
        "}\n",
        "\n",
        "\n",
        "pretrained_settings = deepcopy(pretrained_settings) \n",
        "\n",
        "for model_name, sources in new_settings.items(): \n",
        "    if model_name not in pretrained_settings:\n",
        "        pretrained_settings[model_name] = {} \n",
        "    \n",
        "    for source_name, source_url in sources.items():\n",
        "        pretrained_settings[model_name][source_name] = {\n",
        "            \"url\": source_url,\n",
        "            \"input_size\": [3, 224, 224],\n",
        "            \"input_range\": [0, 1],\n",
        "            \"mean\": [0.485, 0.456, 0.406],\n",
        "            \"std\": [0.229, 0.224, 0.225],\n",
        "            \"num_classes\": 1000,\n",
        "        }\n",
        "\n",
        "resnet_encoders = {\n",
        "    \"resnet18\": {\n",
        "        \"encoder\": ResNetEncoder,\n",
        "        \"pretrained_settings\": pretrained_settings[\"resnet18\"],\n",
        "        \"params\": {\n",
        "            \"out_channels\": (3, 64, 64, 128, 256, 512),\n",
        "            \"block\": BasicBlock,\n",
        "            \"layers\": [2, 2, 2, 2],\n",
        "        },\n",
        "    },\n",
        "    #\"resnet34\": {\n",
        "        #\"encoder\": ResNetEncoder,\n",
        "        #\"pretrained_settings\": pretrained_settings[\"resnet34\"],\n",
        "        #\"params\": {\n",
        "            #\"out_channels\": (3, 64, 64, 128, 256, 512),\n",
        "            #\"block\": BasicBlock,\n",
        "            #\"layers\": [3, 4, 6, 3],\n",
        "        #},\n",
        "    #},\n",
        "    \"resnet50\": {\n",
        "        \"encoder\": ResNetEncoder,\n",
        "        \"pretrained_settings\": pretrained_settings[\"resnet50\"],\n",
        "        \"params\": {\n",
        "            \"out_channels\": (3, 64, 256, 512, 1024, 2048),\n",
        "            \"block\": Bottleneck,\n",
        "            \"layers\": [3, 4, 6, 3],\n",
        "        },\n",
        "    },\n",
        "    #\"resnet101\": {\n",
        "        #\"encoder\": ResNetEncoder,\n",
        "        #\"pretrained_settings\": pretrained_settings[\"resnet101\"],\n",
        "        #\"params\": {\n",
        "            #\"out_channels\": (3, 64, 256, 512, 1024, 2048),\n",
        "            #\"block\": Bottleneck,\n",
        "            #\"layers\": [3, 4, 23, 3],\n",
        "        #},\n",
        "    #},\n",
        "    #\"resnet152\": {\n",
        "        #\"encoder\": ResNetEncoder,\n",
        "        #\"pretrained_settings\": pretrained_settings[\"resnet152\"],\n",
        "        #\"params\": {\n",
        "            #\"out_channels\": (3, 64, 256, 512, 1024, 2048),\n",
        "            #\"block\": Bottleneck,\n",
        "            #\"layers\": [3, 8, 36, 3],\n",
        "        #},\n",
        "    #},\n",
        "    \"resnext50_32x4d\": {\n",
        "        \"encoder\": ResNetEncoder,\n",
        "        \"pretrained_settings\": pretrained_settings[\"resnext50_32x4d\"],\n",
        "        \"params\": {\n",
        "            \"out_channels\": (3, 64, 256, 512, 1024, 2048),\n",
        "            \"block\": Bottleneck,\n",
        "            \"layers\": [3, 4, 6, 3],\n",
        "            \"groups\": 32,\n",
        "            \"width_per_group\": 4,\n",
        "        },\n",
        "    },\n",
        "    \"resnext101_32x4d\": {\n",
        "        \"encoder\": ResNetEncoder,\n",
        "        \"pretrained_settings\": pretrained_settings[\"resnext101_32x4d\"],\n",
        "        \"params\": {\n",
        "            \"out_channels\": (3, 64, 256, 512, 1024, 2048),\n",
        "            \"block\": Bottleneck,\n",
        "            \"layers\": [3, 4, 23, 3],\n",
        "            \"groups\": 32,\n",
        "            \"width_per_group\": 4,\n",
        "        },\n",
        "    },\n",
        "    \"resnext101_32x8d\": {\n",
        "        \"encoder\": ResNetEncoder,\n",
        "        \"pretrained_settings\": pretrained_settings[\"resnext101_32x8d\"],\n",
        "        \"params\": {\n",
        "            \"out_channels\": (3, 64, 256, 512, 1024, 2048),\n",
        "            \"block\": Bottleneck,\n",
        "            \"layers\": [3, 4, 23, 3],\n",
        "            \"groups\": 32,\n",
        "            \"width_per_group\": 8,\n",
        "        },\n",
        "    },\n",
        "    \"resnext101_32x16d\": {\n",
        "        \"encoder\": ResNetEncoder,\n",
        "        \"pretrained_settings\": pretrained_settings[\"resnext101_32x16d\"],\n",
        "        \"params\": {\n",
        "            \"out_channels\": (3, 64, 256, 512, 1024, 2048),\n",
        "            \"block\": Bottleneck,\n",
        "            \"layers\": [3, 4, 23, 3],\n",
        "            \"groups\": 32,\n",
        "            \"width_per_group\": 16,\n",
        "        },\n",
        "    },\n",
        "    \"resnext101_32x32d\": {\n",
        "        \"encoder\": ResNetEncoder,\n",
        "        \"pretrained_settings\": pretrained_settings[\"resnext101_32x32d\"],\n",
        "        \"params\": {\n",
        "            \"out_channels\": (3, 64, 256, 512, 1024, 2048),\n",
        "            \"block\": Bottleneck,\n",
        "            \"layers\": [3, 4, 23, 3],\n",
        "            \"groups\": 32,\n",
        "            \"width_per_group\": 32,\n",
        "        },\n",
        "    },\n",
        "    \"resnext101_32x48d\": {\n",
        "        \"encoder\": ResNetEncoder,\n",
        "        \"pretrained_settings\": pretrained_settings[\"resnext101_32x48d\"],\n",
        "        \"params\": {\n",
        "            \"out_channels\": (3, 64, 256, 512, 1024, 2048),\n",
        "            \"block\": Bottleneck,\n",
        "            \"layers\": [3, 4, 23, 3],\n",
        "            \"groups\": 32,\n",
        "            \"width_per_group\": 48,\n",
        "        },\n",
        "    },\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4VfQEJhvRnmD"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os \n",
        "import sys \n",
        "import math \n",
        "import time \n",
        "import functools \n",
        "\n",
        "\n",
        "import numpy as np \n",
        "\n",
        "import torch.utils.model_zoo as model_zoo \n",
        "\n",
        "#from .resnet import resnet_encoders \n",
        "#from .utils import preprocess_input, TimmUniversalEncoder\n",
        "#from .timm_resnet import timm_resnest_encoders \n",
        "\n",
        "\n",
        "encoders = {} \n",
        "encoders.update(resnet_encoders) \n",
        "\n",
        "def get_encoder(name, in_channels=3, depth=5, weights=None, output_stride=32, **kwargs):\n",
        "\n",
        "    try:\n",
        "        Encoder = encoders[name][\"encoder\"]\n",
        "    except KeyError:\n",
        "        raise KeyError(\"Wrong encoder name `{}`, supported encoders: {}\".format(name, list(encoders.keys()))) \n",
        "    \n",
        "    params = encoders[name][\"params\"] \n",
        "    params.update(depth=depth) \n",
        "    encoder = Encoder(**params)\n",
        "\n",
        "    if weights is not None:\n",
        "        try:\n",
        "            settings = encoders[name][\"pretrained_settings\"][weights] \n",
        "        \n",
        "        except KeyError:\n",
        "            raise KeyError(\n",
        "                \"Wrong pretrained weights `{}` for encoder `{}`. Available options are: {}\".format(\n",
        "                    weights,\n",
        "                    name,\n",
        "                    list(encoders[name][\"pretrained_settings\"].keys()),\n",
        "                )\n",
        "            )\n",
        "        encoder.load_state_dict(model_zoo.load_url(settings[\"url\"])) \n",
        "    \n",
        "    encoder.set_in_channels(in_channels, pretrained=weights is not None)\n",
        "\n",
        "    if output_stride != 32:\n",
        "        encoder.make_dilated(output_stride) \n",
        "    \n",
        "    return encoder \n",
        "\n",
        "\n",
        "def get_encoder_names():\n",
        "    return list(encoders.keys())\n",
        "\n",
        "\n",
        "def get_preprocessing_params(encoder_name, pretrained=\"imagenet\"):\n",
        "\n",
        "    all_settings = encoders[encoder_name][\"pretrained_settings\"]\n",
        "    if pretrained not in all_settings.keys():\n",
        "        raise ValueError(\"Available pretrained options {}\".format(all_settings.keys()))\n",
        "    \n",
        "    settings = all_settings[pretrained]\n",
        "\n",
        "    formatted_settings = {}\n",
        "    formatted_settings[\"input_space\"] = settings.get(\"input_space\", \"RGB\")\n",
        "    formatted_settings[\"input_range\"] = list(settings.get(\"input_range\", [0, 1]))\n",
        "    formatted_settings[\"mean\"] = list(settings.get(\"mean\"))\n",
        "    formatted_settings[\"std\"] = list(settings.get(\"std\"))\n",
        "\n",
        "    return formatted_settings\n",
        "\n",
        "\n",
        "def get_preprocessing_fn(encoder_name, pretrained=\"imagenet\"):\n",
        "    params = get_preprocessing_params(encoder_name, pretrained=pretrained)\n",
        "    return functools.partial(preprocess_input, **params)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#image augmentation\n",
        "import torchvision.transforms as transforms\n",
        "mean=0.5\n",
        "std_deviation=0.5\n",
        "\n",
        "CHANNELS_IMG=3\n",
        "transforms = transforms.Compose(\n",
        "    [\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.Resize(256),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([mean for _ in range(CHANNELS_IMG)],[std_deviation for _ in range(CHANNELS_IMG)]),\n",
        "     \n",
        "     ]\n",
        ")"
      ],
      "metadata": {
        "id": "ZiwobdX_XF01"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwlx1_JXV4A4",
        "outputId": "11f2a948-5582-4e98-818b-90e3237bb0c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1356\n",
            "torch.Size([3, 640, 640]) torch.Size([1, 640, 640]) tensor(2.6400, dtype=torch.float64) tensor(1.) tensor(-2.1179, dtype=torch.float64) tensor(0.)\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "import sys \n",
        "import math\n",
        "\n",
        "import cv2 \n",
        "import glob \n",
        "import random \n",
        "\n",
        "import numpy as np \n",
        "\n",
        "import torch \n",
        "import torch.utils.data as data \n",
        "\n",
        "\n",
        "class BrainTumorDataset(data.Dataset):\n",
        "    def __init__(self, datafolder='/content/gdrive/MyDrive/data/notumor', transforms = transforms, train=True, \n",
        "                        image_size=(640, 640), train_test_ratio=0.15, preprocessing_fun=None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.train = train \n",
        "        self.transform = transforms \n",
        "        self.image_size = image_size\n",
        "        self.train_test_ratio = train_test_ratio \n",
        "        self.preprocessing_fun = preprocessing_fun \n",
        "\n",
        "        image_names = [ ]\n",
        "        image_names_jpg = glob.glob(os.path.join(datafolder, '*.jpg'))  \n",
        "        image_names_jpeg = glob.glob(os.path.join(datafolder, '*.jpeg'))  \n",
        "        image_names_png  = glob.glob(os.path.join(datafolder, '*.png')) \n",
        "        image_names.extend(image_names_jpg)  \n",
        "        image_names.extend(image_names_jpeg) \n",
        "        image_names.extend(image_names_png) \n",
        "\n",
        "        Num_testSamples = int(train_test_ratio*len(image_names)) \n",
        "        random.seed(42) \n",
        "        random.shuffle(image_names) \n",
        "\n",
        "        if self.train: \n",
        "            self.image_names = image_names[Num_testSamples:] \n",
        "        else: \n",
        "            self.image_names = image_names[:Num_testSamples] \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.image_names) \n",
        "    \n",
        "    def read_image(self, image_name): \n",
        "        img = cv2.imread(image_name, cv2.IMREAD_GRAYSCALE) \n",
        "        try:\n",
        "            Img = cv2.resize(img, self.image_size, cv2.INTER_CUBIC) \n",
        "            Img = 255.0*(Img/ Img.max()) \n",
        "            return Img \n",
        "        except:\n",
        "            raise ValueError('Image not found') \n",
        "        \n",
        "    def add_rice_noise(self, img, snr=10, mu=0.1, sigma=1):\n",
        "        level = snr* np.max(img) / 100 \n",
        "        size = img.shape \n",
        "        x = level* np.random.normal(mu, sigma, size=size) + img \n",
        "        y = level * np.random.normal(mu, sigma, size=size) \n",
        "        return np.sqrt(x**2 + y**2).astype(np.int16)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        image_name = self.image_names[index] \n",
        "        Img = self.read_image(image_name)\n",
        "        Img_noisy = self.add_rice_noise(Img) \n",
        "\n",
        "        Img_noisy = np.stack([Img_noisy, Img_noisy, Img_noisy], axis=-1) \n",
        "        Img = np.expand_dims(Img, axis=-1) \n",
        "\n",
        "\n",
        "        Img = torch.from_numpy(Img).to(torch.float32) \n",
        "        Img_noisy = torch.from_numpy(Img_noisy).to(torch.float32)\n",
        "\n",
        "        Img = Img/ Img.max() \n",
        "        Img_noisy = (Img_noisy - Img_noisy.min()) / (Img_noisy.max() - Img_noisy.min()) \n",
        "        if self.preprocessing_fun:\n",
        "            Img_noisy = self.preprocessing_fun(Img_noisy) \n",
        "        \n",
        "        Img_noisy = Img_noisy.permute(2, 0, 1) \n",
        "        Img = Img.permute(2, 0, 1) \n",
        "        return Img_noisy, Img  \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    #from encoder.encoder_model import get_preprocessing_fn \n",
        "    encoder_name = 'resnet18'\n",
        "    preprocessing =  get_preprocessing_fn(encoder_name=encoder_name, pretrained='ssl')\n",
        "    dataset = BrainTumorDataset(preprocessing_fun=preprocessing) \n",
        "    print(len(dataset))\n",
        "    Img_noisy, Img = dataset[0] \n",
        "    print(Img_noisy.shape, Img.shape, Img_noisy.max(), Img.max(), Img_noisy.min(), Img.min())\n",
        "\n",
        "    #cv2.imshow('noisy image', np.uint8(255*Img_noisy.numpy().transpose(1, 2, 0)[:,:, 0])) \n",
        "    #cv2.imshow('ground image', np.uint8(255*Img.numpy().transpose(1, 2, 0))) \n",
        "    cv2.waitKey(0) \n",
        "    cv2.destroyAllWindows() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4AyyY4R9WZCu"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import sys \n",
        "import math \n",
        "\n",
        "import numpy as np \n",
        "\n",
        "import torch \n",
        "import torch.nn as nn  \n",
        "\n",
        "def initialize_decoder(module): \n",
        "    for m in module.modules():\n",
        "\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            nn.init.kaiming_uniform_(m.weight, mode=\"fan_in\", nonlinearity=\"relu\") \n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0) \n",
        "        \n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            nn.init.constant_(m.weight, 1)\n",
        "            nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0) \n",
        "\n",
        "\n",
        "def initialize_head(module):\n",
        "    for m in module.modules():\n",
        "        if isinstance(m, (nn.Linear, nn.Conv2d)):\n",
        "            nn.init.xavier_uniform_(m.weight)\n",
        "            if m.bias is not None:\n",
        "                nn.init.constant_(m.bias, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JU7YU89OopW_"
      },
      "outputs": [],
      "source": [
        "import os  \n",
        "import sys \n",
        "import math \n",
        "\n",
        "import numpy as np \n",
        "\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F \n",
        "\n",
        "try:\n",
        "    from inplace_abn import InPlaceABN \n",
        "except ImportError:\n",
        "    InPlaceABN = None  \n",
        "\n",
        "class Conv2dReLU(nn.Sequential):\n",
        "    def __init__( self,   in_channels,   out_channels, kernel_size, padding=0,   stride=1,   use_batchnorm=True, ): \n",
        "        conv = nn.Conv2d(in_channels,   out_channels,  kernel_size, \n",
        "                  stride=stride,   padding=padding,  bias=not (use_batchnorm), ) \n",
        "        \n",
        "        relu = nn.ReLU(inplace=True)\n",
        "        if use_batchnorm:\n",
        "            bn = nn.BatchNorm2d(out_channels)  \n",
        "        else:\n",
        "            bn = nn.Identity() \n",
        "        super(Conv2dReLU, self).__init__(conv, bn, relu)\n",
        "\n",
        "\n",
        "class SCSEModule(nn.Module):\n",
        "    def __init__(self, in_channels, reduction=16):\n",
        "        super().__init__() \n",
        "        self.cSE = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Conv2d(in_channels, in_channels//reduction, 1), \n",
        "            nn.ReLU(inplace=True), \n",
        "            nn.Conv2d(in_channels//reduction, in_channels, 1), \n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.sSE =  nn.Sequential(nn.Conv2d(in_channels, 1, 1), nn.Sigmoid()) \n",
        "    \n",
        "    def forward(self, x):\n",
        "        return x * self.cSE(x) + x * self.sSE(x) \n",
        "\n",
        "\n",
        "class DecoderBlock(nn.Module): \n",
        "    def __init__( self,  in_channels,  skip_channels,  out_channels,  use_batchnorm=True):  \n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = Conv2dReLU( in_channels + skip_channels, out_channels, kernel_size=3, padding=1,\n",
        "                                 use_batchnorm=use_batchnorm, ) \n",
        "        \n",
        "        self.attention1 = SCSEModule(in_channels=in_channels + skip_channels) \n",
        "        self.conv2 = Conv2dReLU( out_channels, out_channels, kernel_size=3, padding=1, use_batchnorm=use_batchnorm,) \n",
        "        self.attention2 = SCSEModule( in_channels=out_channels)\n",
        "    \n",
        "    def forward(self, x, skip=None):\n",
        "        x = F.interpolate(x, scale_factor=2, mode=\"nearest\") \n",
        "        if skip is not None:\n",
        "            x = torch.cat([x, skip], dim=1) \n",
        "            x = self.attention1(x) \n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.attention2(x) \n",
        "        return x \n",
        "\n",
        "\n",
        "class UnetDecoder(nn.Module): \n",
        "    def __init__( self, encoder_channels, decoder_channels, n_blocks=5, use_batchnorm=True,):\n",
        "        super().__init__() \n",
        "\n",
        "        if n_blocks != len(decoder_channels):\n",
        "            raise ValueError(\"Model depth is {}, but you provide `decoder_channels` for {} blocks.\".format(\n",
        "                    n_blocks, len(decoder_channels))) \n",
        "        \n",
        "        encoder_channels = encoder_channels[1:]\n",
        "        encoder_channels = encoder_channels[::-1]\n",
        "\n",
        "        head_channels = encoder_channels[0]\n",
        "        in_channels = [head_channels] + list(decoder_channels[:-1]) \n",
        "        skip_channels = list(encoder_channels[1:]) + [0]  \n",
        "        out_channels = decoder_channels  \n",
        "\n",
        "        blocks = [ DecoderBlock(in_ch, skip_ch, out_ch, use_batchnorm=use_batchnorm)\n",
        "            for in_ch, skip_ch, out_ch in zip(in_channels, skip_channels, out_channels)\n",
        "        ]\n",
        "        self.blocks = nn.ModuleList(blocks)\n",
        "\n",
        "    def forward(self, *features):\n",
        "        \n",
        "        features = features[1:] \n",
        "        features = features[::-1] \n",
        "        x = features[0] \n",
        "        skips = features[1:] \n",
        "\n",
        "        for i, decoder_block in enumerate(self.blocks):\n",
        "            skip = skips[i] if i < len(skips) else None\n",
        "            x = decoder_block(x, skip) \n",
        "        return x \n",
        "\n",
        "\n",
        "#if __name__ == '__main__': \n",
        "    #model = UnetDecoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLSLNzT6X-Mu",
        "outputId": "15f4db48-d4d7-481e-8ba8-9a91750e09ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "UNeT(\n",
            "  (encoder): ResNetEncoder(\n",
            "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    (layer1): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): BasicBlock(\n",
            "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (downsample): Sequential(\n",
            "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        )\n",
            "      )\n",
            "      (1): BasicBlock(\n",
            "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (relu): ReLU(inplace=True)\n",
            "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (decoder): UnetDecoder(\n",
            "    (blocks): ModuleList(\n",
            "      (0): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): SCSEModule(\n",
            "          (cSE): Sequential(\n",
            "            (0): AdaptiveAvgPool2d(output_size=1)\n",
            "            (1): Conv2d(768, 48, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): Conv2d(48, 768, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (4): Sigmoid()\n",
            "          )\n",
            "          (sSE): Sequential(\n",
            "            (0): Conv2d(768, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): SCSEModule(\n",
            "          (cSE): Sequential(\n",
            "            (0): AdaptiveAvgPool2d(output_size=1)\n",
            "            (1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): Conv2d(16, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (4): Sigmoid()\n",
            "          )\n",
            "          (sSE): Sequential(\n",
            "            (0): Conv2d(256, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (1): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): SCSEModule(\n",
            "          (cSE): Sequential(\n",
            "            (0): AdaptiveAvgPool2d(output_size=1)\n",
            "            (1): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (4): Sigmoid()\n",
            "          )\n",
            "          (sSE): Sequential(\n",
            "            (0): Conv2d(384, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): SCSEModule(\n",
            "          (cSE): Sequential(\n",
            "            (0): AdaptiveAvgPool2d(output_size=1)\n",
            "            (1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (4): Sigmoid()\n",
            "          )\n",
            "          (sSE): Sequential(\n",
            "            (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (2): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): SCSEModule(\n",
            "          (cSE): Sequential(\n",
            "            (0): AdaptiveAvgPool2d(output_size=1)\n",
            "            (1): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (4): Sigmoid()\n",
            "          )\n",
            "          (sSE): Sequential(\n",
            "            (0): Conv2d(192, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): SCSEModule(\n",
            "          (cSE): Sequential(\n",
            "            (0): AdaptiveAvgPool2d(output_size=1)\n",
            "            (1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (4): Sigmoid()\n",
            "          )\n",
            "          (sSE): Sequential(\n",
            "            (0): Conv2d(64, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (3): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): SCSEModule(\n",
            "          (cSE): Sequential(\n",
            "            (0): AdaptiveAvgPool2d(output_size=1)\n",
            "            (1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (4): Sigmoid()\n",
            "          )\n",
            "          (sSE): Sequential(\n",
            "            (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): SCSEModule(\n",
            "          (cSE): Sequential(\n",
            "            (0): AdaptiveAvgPool2d(output_size=1)\n",
            "            (1): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (4): Sigmoid()\n",
            "          )\n",
            "          (sSE): Sequential(\n",
            "            (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (4): DecoderBlock(\n",
            "        (conv1): Conv2dReLU(\n",
            "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention1): SCSEModule(\n",
            "          (cSE): Sequential(\n",
            "            (0): AdaptiveAvgPool2d(output_size=1)\n",
            "            (1): Conv2d(32, 2, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): Conv2d(2, 32, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (4): Sigmoid()\n",
            "          )\n",
            "          (sSE): Sequential(\n",
            "            (0): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "        (conv2): Conv2dReLU(\n",
            "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "          (2): ReLU(inplace=True)\n",
            "        )\n",
            "        (attention2): SCSEModule(\n",
            "          (cSE): Sequential(\n",
            "            (0): AdaptiveAvgPool2d(output_size=1)\n",
            "            (1): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (2): ReLU(inplace=True)\n",
            "            (3): Conv2d(1, 16, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (4): Sigmoid()\n",
            "          )\n",
            "          (sSE): Sequential(\n",
            "            (0): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1))\n",
            "            (1): Sigmoid()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (output): OutputLayer(\n",
            "    (0): Conv2d(16, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            ")\n",
            "torch.Size([1, 1, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "import sys \n",
        "import math\n",
        "\n",
        "\n",
        "import numpy as np \n",
        "\n",
        "from typing import List \n",
        "\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "\n",
        "#from encoder.encoder_model import get_encoder\n",
        "#from modules import UnetDecoder \n",
        "#from initialization import initialize_decoder, initialize_head \n",
        "\n",
        "\n",
        "class OutputLayer(nn.Sequential):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, activation=None):  \n",
        "        conv2d = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size // 2) \n",
        "        super().__init__(conv2d)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class UNeT(nn.Module):\n",
        "    def __init__(self, encoder_name: str = \"resnet18\",  encoder_depth: int = 5,in_channels: int = 3,\n",
        "                   decoder_channels: List[int] = (256, 128, 64, 32, 16),): \n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = get_encoder(encoder_name, in_channels=in_channels, depth=encoder_depth) \n",
        "        self.decoder = UnetDecoder(self.encoder.out_channels, decoder_channels=decoder_channels, n_blocks= encoder_depth) \n",
        "        self.output  = OutputLayer(decoder_channels[-1], out_channels=1) \n",
        "        self.iniitialize() \n",
        "    \n",
        "    def check_input_shape(self, x):\n",
        "        h, w = x.shape[-2:]\n",
        "        output_stride = self.encoder.output_stride\n",
        "        if h % output_stride != 0 or w % output_stride != 0:\n",
        "            new_h = (h // output_stride + 1) * output_stride if h % output_stride != 0 else h\n",
        "            new_w = (w // output_stride + 1) * output_stride if w % output_stride != 0 else w\n",
        "            raise RuntimeError(f\"Wrong input shape height={h}, width={w}. Expected image height and width \"\n",
        "                f\"divisible by {output_stride}. Consider pad your images to shape ({new_h}, {new_w}).\")\n",
        "\n",
        "    def iniitialize(self): \n",
        "        initialize_decoder(self.decoder) \n",
        "        initialize_head(self.output) \n",
        "\n",
        "    def forward(self, x): \n",
        "        self.check_input_shape(x) \n",
        "        features = self.encoder(x) \n",
        "        decoder_output = self.decoder(*features) \n",
        "        output = self.output(decoder_output) \n",
        "        return output \n",
        "\n",
        "if __name__ == '__main__': \n",
        "    model  =UNeT() \n",
        "    print(model)\n",
        "\n",
        "    x = torch.randn(1, 3, 224, 224) \n",
        "    out = model(x) \n",
        "    print(out.shape) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyQHuYjepAVc"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import sys \n",
        "import math \n",
        "\n",
        "import cv2 \n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "\n",
        "import torchvision \n",
        "\n",
        "class VGGPerceptualLoss(torch.nn.Module):\n",
        "    def __init__(self, resize=True):\n",
        "        super(VGGPerceptualLoss, self).__init__()\n",
        "        blocks = [ ] \n",
        "        blocks.append(torchvision.models.vgg16(pretrained=True).features[:4].eval())\n",
        "        blocks.append(torchvision.models.vgg16(pretrained=True).features[4:9].eval())\n",
        "        blocks.append(torchvision.models.vgg16(pretrained=True).features[9:16].eval())\n",
        "        blocks.append(torchvision.models.vgg16(pretrained=True).features[16:23].eval())\n",
        "\n",
        "        for bl in blocks:\n",
        "            for p in bl.parameters(): \n",
        "                p.requires_grad = False \n",
        "        \n",
        "        self.blocks = torch.nn.ModuleList(blocks)\n",
        "        self.transform = torch.nn.functional.interpolate\n",
        "        self.resize = resize\n",
        "        self.register_buffer(\"mean\", torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1))\n",
        "        self.register_buffer(\"std\", torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)) \n",
        "    \n",
        "    def forward(self, input_image, target, feature_layers=[0, 1, 2, 3], style_layers=[]):\n",
        "        if input_image.shape[1] != 3:\n",
        "            input_image = input_image.repeat(1, 3, 1, 1)\n",
        "            target = target.repeat(1, 3, 1, 1)\n",
        "        \n",
        "        input_image = (input_image - self.mean) / self.std\n",
        "        target = (target - self.mean) / self.std \n",
        "        if self.resize:\n",
        "            input_image = self.transform(input_image, mode='bilinear', size=(224, 224), align_corners=False) \n",
        "            target = self.transform(target, mode='bilinear', size=(224, 224), align_corners=False) \n",
        "        \n",
        "        loss = 0.0\n",
        "        x = input_image \n",
        "        y = target\n",
        "        for i, block in enumerate(self.blocks):\n",
        "            x = block(x)\n",
        "            y = block(y) \n",
        "            if i in feature_layers:\n",
        "                loss += torch.nn.functional.l1_loss(x, y) \n",
        "            \n",
        "            if i in style_layers:\n",
        "                act_x = x.reshape(x.shape[0], x.shape[1], -1)\n",
        "                act_y = y.reshape(y.shape[0], y.shape[1], -1)\n",
        "                gram_x = act_x @ act_x.permute(0, 2, 1)\n",
        "                gram_y = act_y @ act_y.permute(0, 2, 1) \n",
        "                loss += torch.nn.functional.l1_loss(gram_x, gram_y) \n",
        "        \n",
        "        return loss "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8N51goAgpEq0"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def gaussian(window_size, sigma):\n",
        "    gauss = torch.Tensor(\n",
        "        [\n",
        "            math.exp(-((x - window_size // 2) ** 2) / float(2 * sigma ** 2))\n",
        "            for x in range(window_size)\n",
        "        ]\n",
        "    )\n",
        "    return gauss / gauss.sum()\n",
        "\n",
        "\n",
        "def create_window(window_size, channel=1):\n",
        "\n",
        "    _1D_window = gaussian(window_size, 1.5).unsqueeze(1)\n",
        "    _2D_window = _1D_window.mm(_1D_window.t()).float() \n",
        "    _2D_window /= _2D_window.sum() \n",
        "    _2D_window = _2D_window.unsqueeze(0).unsqueeze(0)\n",
        "\n",
        "    window = torch.Tensor(\n",
        "        _2D_window.expand(channel, 1, window_size, window_size).contiguous()\n",
        "    )\n",
        "\n",
        "    return window\n",
        "\n",
        "\n",
        "def ssim(\n",
        "    img1, img2, val_range, window_size=11, window=None, size_average=True, full=False):\n",
        "\n",
        "    L = val_range  # L is the dynamic range of the pixel values (255 for 8-bit grayscale images),\n",
        "\n",
        "    pad = window_size // 2\n",
        "\n",
        "    try:\n",
        "        _, channels, height, width = img1.size()\n",
        "    except:\n",
        "        channels, height, width = img1.size()\n",
        "\n",
        "    # if window is not provided, init one\n",
        "    if window is None:\n",
        "        real_size = min(window_size, height, width)  # window should be atleast 11x11\n",
        "        window = create_window(real_size, channel=channels).to(img1.device)\n",
        "\n",
        "    # calculating the mu parameter (locally) for both images using a gaussian filter\n",
        "    # calculates the luminosity params\n",
        "    mu1 = F.conv2d(img1, window, padding=pad, groups=channels)\n",
        "    mu2 = F.conv2d(img2, window, padding=pad, groups=channels)\n",
        "\n",
        "    mu1_sq = mu1 ** 2\n",
        "    mu2_sq = mu2 ** 2\n",
        "    mu12 = mu1 * mu2\n",
        "\n",
        "    # now we calculate the sigma square parameter\n",
        "    # Sigma deals with the contrast component\n",
        "    sigma1_sq = F.conv2d(img1 * img1, window, padding=pad, groups=channels) - mu1_sq\n",
        "    sigma2_sq = F.conv2d(img2 * img2, window, padding=pad, groups=channels) - mu2_sq\n",
        "    sigma12 = F.conv2d(img1 * img2, window, padding=pad, groups=channels) - mu12\n",
        "\n",
        "    # Some constants for stability\n",
        "    C1 = (0.01) ** 2  # NOTE: Removed L from here (ref PT implementation)\n",
        "    C2 = (0.03) ** 2\n",
        "\n",
        "    contrast_metric = (2.0 * sigma12 + C2) / (sigma1_sq + sigma2_sq + C2)\n",
        "    contrast_metric = torch.mean(contrast_metric)\n",
        "\n",
        "    numerator1 = 2 * mu12 + C1\n",
        "    numerator2 = 2 * sigma12 + C2\n",
        "    denominator1 = mu1_sq + mu2_sq + C1\n",
        "    denominator2 = sigma1_sq + sigma2_sq + C2\n",
        "\n",
        "    ssim_score = (numerator1 * numerator2) / (denominator1 * denominator2)\n",
        "\n",
        "    if size_average:\n",
        "        ret = ssim_score.mean()\n",
        "    else:\n",
        "        ret = ssim_score.mean(1).mean(1).mean(1)\n",
        "\n",
        "    if full:\n",
        "        return ret, contrast_metric\n",
        "\n",
        "    return ret"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QwZLasppI5L"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import sys \n",
        "import math \n",
        "\n",
        "import numpy as np \n",
        "\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F \n",
        "\n",
        "import torchvision \n",
        "\n",
        "\n",
        "def save_model(checkpoint, checkpoint_path):\n",
        "    torch.save(checkpoint, checkpoint_path) \n",
        "\n",
        "def load_checkpoint(checkpoint_path, model, model_opt): \n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    model_opt.optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    return model, model_opt, checkpoint['epoch']\n",
        "\n",
        "\n",
        "def save_figure(model, loader, epoch, device, mean = [0.485, 0.456, 0.406], std= [0.229, 0.224, 0.225]):\n",
        "    model.eval() \n",
        "\n",
        "    if not os.path.exists(os.path.join(os.getcwd(), 'save_results')):\n",
        "        os.mkdir(os.path.join(os.getcwd(), 'save_results')) \n",
        "\n",
        "    result_dir = os.path.join(os.getcwd(), 'save_results')\n",
        "    if not os.path.exists(os.path.join(result_dir, str(epoch))):\n",
        "        os.mkdir(os.path.join(result_dir, str(epoch))) \n",
        "\n",
        "    save_dir = os.path.join(result_dir, str(epoch))\n",
        "    for idx, (x, y) in enumerate(loader):\n",
        "        x = x.to(device).float()  \n",
        "        with torch.no_grad():\n",
        "            out = torch.sigmoid(model(x))  \n",
        "            torchvision.utils.save_image(out[2,:], f\"{save_dir}/pred_{idx}.png\") \n",
        "            torchvision.utils.save_image(y[2,:],  f\"{save_dir}/target_{idx}.png\")\n",
        "            x = x.permute(0, 2, 3, 1).cpu().numpy() \n",
        "            x = (x *np.array(std)) + np.array(mean) \n",
        "            x = x / x.max() \n",
        "            x = np.transpose(x, (0, 3, 1, 2)) \n",
        "            x = torch.from_numpy(x).float().to(device)\n",
        "            torchvision.utils.save_image(x[2,:], f\"{save_dir}/pnoisy_{idx}.png\")\n",
        "        break \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159,
          "referenced_widgets": [
            "bbce8d8da68b472cac9f34ec6ad3eb21",
            "9470d6de3fbc4e92bd0f32ca21a97980",
            "f260706213e64beeb338ce2f777023f4",
            "9657c93b8c724add96ed41ce1c6c5ae4",
            "e6f1c28fbeb54dfdb9d05bd837d8a343",
            "141e3b4795194e04980e86e292750e7b",
            "e048570862be41cc9aa293811a958da4",
            "a34277f83ad545cb876d7d9b2ec9f3fe",
            "1e2d696f1f8f40f8b9d7ebfcd5d99587",
            "40c5185dd0f04d7d907d731e1446d492",
            "d6e7d301ffc74f4f88df86d07525d317"
          ]
        },
        "id": "gD6tvrkXW3SB",
        "outputId": "6be6339c-241a-4dfc-ea4a-4e543f92f237"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bbce8d8da68b472cac9f34ec6ad3eb21"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import os \n",
        "import sys \n",
        "import math \n",
        "\n",
        "import numpy as np \n",
        "\n",
        "from tqdm import tqdm \n",
        "\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim \n",
        "\n",
        "#from ssim import ssim \n",
        "#from PerceptualLoss import  VGGPerceptualLoss \n",
        "\n",
        "criterion = VGGPerceptualLoss() \n",
        "\n",
        "def train(model, loader, optimizer, device, ):\n",
        "   \n",
        "    model.train() \n",
        "    training_loss = 0.0 \n",
        "    avg_ssim = 0.0 \n",
        "    criterion = VGGPerceptualLoss()\n",
        "\n",
        "    for i ,(x, y) in tqdm(enumerate(loader), total=len(loader), leave=False):\n",
        "\n",
        "        x = x.to(device).float() \n",
        "        y = y.to(device).float() \n",
        "        criterion = criterion.to(device) \n",
        "\n",
        "        out = torch.sigmoid(model(x)) \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        metrics = ssim(out, y, 1)  \n",
        "        loss   = criterion(out, y)\n",
        "        \n",
        "        loss.backward() \n",
        "        optimizer.step() \n",
        "\n",
        "        training_loss += loss.item() \n",
        "        avg_ssim += metrics.item() \n",
        "    \n",
        "    training_loss = training_loss / len(loader) \n",
        "    avg_ssim      = avg_ssim / len(loader) \n",
        "    return model, training_loss, avg_ssim \n",
        "\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval() \n",
        "    val_loss = 0.0 \n",
        "    avg_ssim = 0.0 \n",
        "    criterion = VGGPerceptualLoss()\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for i ,(x, y) in tqdm(enumerate(loader), total=len(loader), leave=False):\n",
        "\n",
        "            x = x.to(device).float() \n",
        "            y = y.to(device).float() \n",
        "            criterion = criterion.to(device) \n",
        "\n",
        "            out = model(x) \n",
        "            out = torch.sigmoid(out) \n",
        "\n",
        "            metrics = ssim(out, y, 1) \n",
        "            loss = criterion(out, y)\n",
        "            \n",
        "\n",
        "            val_loss      += loss.item() \n",
        "            avg_ssim      += metrics.item() \n",
        "    \n",
        "        val_loss = val_loss / len(loader) \n",
        "        avg_ssim = avg_ssim / len(loader) \n",
        "        return model, val_loss, avg_ssim "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoRHwUf7Wbgx",
        "outputId": "cdd9a15e-d062-41ff-bc3e-0084a5a7d0b7"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79 13\n",
            "20 4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0 Training loss 2.2969790756702424 training ssim 0.3162378935143352                   validation loss 2.872429609298706 and testing ssim 0.3381417766213417\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 1 Training loss 1.6275945782661438 training ssim 0.4506705731153488                   validation loss 1.94084894657135 and testing ssim 0.45006105303764343\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 2 Training loss 1.524696844816208 training ssim 0.4796126842498779                   validation loss 1.4468362033367157 and testing ssim 0.5024911388754845\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 3 Training loss 1.4573120415210723 training ssim 0.5112960338592529                   validation loss 1.517081469297409 and testing ssim 0.5178531855344772\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 4 Training loss 1.3754127144813537 training ssim 0.5466333597898483                   validation loss 1.4667218923568726 and testing ssim 0.5476851537823677\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 5 Training loss 1.3050914704799652 training ssim 0.599681892991066                   validation loss 1.3370575308799744 and testing ssim 0.6300772577524185\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 6 Training loss 1.2307878851890564 training ssim 0.6345154270529747                   validation loss 1.2364865243434906 and testing ssim 0.6547175496816635\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 7 Training loss 1.2147377192974091 training ssim 0.6607534974813462                   validation loss 1.205882489681244 and testing ssim 0.6970089077949524\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 8 Training loss 1.1644049286842346 training ssim 0.6823882564902306                   validation loss 1.135597437620163 and testing ssim 0.704770565032959\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 9 Training loss 1.1647705852985382 training ssim 0.690118308365345                   validation loss 1.1461351066827774 and testing ssim 0.7119907587766647\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 10 Training loss 1.1391616702079772 training ssim 0.7041080832481384                   validation loss 1.1060389578342438 and testing ssim 0.7314828932285309\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 11 Training loss 1.131676584482193 training ssim 0.7071890398859978                   validation loss 1.1555549204349518 and testing ssim 0.7280284315347672\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 12 Training loss 1.1081255286931992 training ssim 0.7193607926368714                   validation loss 1.106448620557785 and testing ssim 0.7434744387865067\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 13 Training loss 1.104638609290123 training ssim 0.7161433696746826                   validation loss 1.0918320268392563 and testing ssim 0.7433414459228516\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 14 Training loss 1.0930209755897522 training ssim 0.7322126775979996                   validation loss 1.185074895620346 and testing ssim 0.7557826787233353\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 15 Training loss 1.0983656406402589 training ssim 0.720832833647728                   validation loss 1.081295520067215 and testing ssim 0.7531385570764542\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 16 Training loss 1.0843219250440597 training ssim 0.7223053365945816                   validation loss 1.0885253846645355 and testing ssim 0.740352526307106\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 17 Training loss 1.0869628071784974 training ssim 0.7436172604560852                   validation loss 1.086094319820404 and testing ssim 0.7511025965213776\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 18 Training loss 1.0761562883853912 training ssim 0.7446792632341385                   validation loss 1.0852361619472504 and testing ssim 0.7578654885292053\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 19 Training loss 1.0693695068359375 training ssim 0.7421977311372757                   validation loss 1.0910667777061462 and testing ssim 0.7560254484415054\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 20 Training loss 1.053443592786789 training ssim 0.7423663347959518                   validation loss 1.06776662170887 and testing ssim 0.7496851682662964\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 21 Training loss 1.0451570868492126 training ssim 0.7494997501373291                   validation loss 1.057245522737503 and testing ssim 0.7616738677024841\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 22 Training loss 1.0465083837509155 training ssim 0.7391541123390197                   validation loss 1.0826347917318344 and testing ssim 0.760383814573288\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 23 Training loss 1.0602323949337005 training ssim 0.7537183463573456                   validation loss 1.35051029920578 and testing ssim 0.7219567149877548\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 24 Training loss 1.0527801662683487 training ssim 0.76172633767128                   validation loss 1.066937193274498 and testing ssim 0.7603003531694412\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 25 Training loss 1.0453800797462462 training ssim 0.750177463889122                   validation loss 1.0644408613443375 and testing ssim 0.767890676856041\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 26 Training loss 1.035258486866951 training ssim 0.7583598703145981                   validation loss 1.0748587995767593 and testing ssim 0.788349062204361\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 27 Training loss 1.0408329337835311 training ssim 0.7497803509235382                   validation loss 1.0592928230762482 and testing ssim 0.7643837779760361\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 28 Training loss 1.0519518733024598 training ssim 0.757340383529663                   validation loss 1.0937653481960297 and testing ssim 0.7601088136434555\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 29 Training loss 1.0441552370786666 training ssim 0.7538594633340836                   validation loss 1.0463737845420837 and testing ssim 0.7789901345968246\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 30 Training loss 1.0341661810874938 training ssim 0.7583784133195877                   validation loss 1.043801173567772 and testing ssim 0.7892549782991409\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 31 Training loss 1.0283174514770508 training ssim 0.7607487380504608                   validation loss 1.066094309091568 and testing ssim 0.791974201798439\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 32 Training loss 1.0289112001657486 training ssim 0.7617306798696518                   validation loss 1.0552009791135788 and testing ssim 0.7859044820070267\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 33 Training loss 1.0274487495422364 training ssim 0.7610794335603714                   validation loss 1.0397187620401382 and testing ssim 0.7796945869922638\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 34 Training loss 1.0232686549425125 training ssim 0.7650157690048218                   validation loss 1.0336983650922775 and testing ssim 0.7910946160554886\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 35 Training loss 1.0228184789419175 training ssim 0.7570869475603104                   validation loss 1.0564260333776474 and testing ssim 0.7801585048437119\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 36 Training loss 1.0179831862449646 training ssim 0.7722863227128982                   validation loss 1.0449548363685608 and testing ssim 0.7813116312026978\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 37 Training loss 1.0189955860376358 training ssim 0.7665986329317093                   validation loss 1.0607614070177078 and testing ssim 0.771391972899437\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 38 Training loss 1.0190556317567825 training ssim 0.7638083547353745                   validation loss 1.0538355857133865 and testing ssim 0.7724195718765259\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 39 Training loss 1.0217517524957658 training ssim 0.7696290165185928                   validation loss 1.033608078956604 and testing ssim 0.7923179119825363\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 40 Training loss 1.0135761857032777 training ssim 0.7632142156362534                   validation loss 1.0884445160627365 and testing ssim 0.769161656498909\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 41 Training loss 1.0168974459171296 training ssim 0.7711908161640167                   validation loss 1.0592349469661713 and testing ssim 0.7697439938783646\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 42 Training loss 1.009822455048561 training ssim 0.762781634926796                   validation loss 1.0434496700763702 and testing ssim 0.7779793739318848\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 43 Training loss 1.007825419306755 training ssim 0.7694134920835495                   validation loss 1.1110946089029312 and testing ssim 0.7619140595197678\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 44 Training loss 1.0083904027938844 training ssim 0.777655017375946                   validation loss 1.042612224817276 and testing ssim 0.7770475149154663\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 45 Training loss 1.0025452435016633 training ssim 0.7634640514850617                   validation loss 1.061383694410324 and testing ssim 0.7772463113069534\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 46 Training loss 1.0071590006351472 training ssim 0.7689954191446304                   validation loss 1.0517596304416656 and testing ssim 0.7926216423511505\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 47 Training loss 0.9957260519266129 training ssim 0.7711000949144363                   validation loss 1.0315636843442917 and testing ssim 0.78763847053051\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 48 Training loss 0.9930047512054443 training ssim 0.7789777100086213                   validation loss 1.040807843208313 and testing ssim 0.7863055765628815\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 49 Training loss 1.0048123359680177 training ssim 0.7751099854707718                   validation loss 1.053008183836937 and testing ssim 0.7717155069112778\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 50 Training loss 0.9924394488334656 training ssim 0.7660247057676315                   validation loss 1.0312540531158447 and testing ssim 0.7898129373788834\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 51 Training loss 0.9820368349552154 training ssim 0.7835296303033829                   validation loss 1.0404072254896164 and testing ssim 0.7814449965953827\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 52 Training loss 0.9909661442041398 training ssim 0.7850148439407348                   validation loss 1.0394653677940369 and testing ssim 0.7841162383556366\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 53 Training loss 0.9952596843242645 training ssim 0.7744616121053696                   validation loss 1.0487912744283676 and testing ssim 0.7785352468490601\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 54 Training loss 0.9833147197961807 training ssim 0.7760499566793442                   validation loss 1.0439806133508682 and testing ssim 0.7936396151781082\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 55 Training loss 0.9853033214807511 training ssim 0.7790079951286316                   validation loss 1.039762407541275 and testing ssim 0.7983435541391373\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 56 Training loss 0.976248151063919 training ssim 0.7753547042608261                   validation loss 1.0945442616939545 and testing ssim 0.7660123854875565\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 57 Training loss 0.9900408267974854 training ssim 0.7749443858861923                   validation loss 1.0462831109762192 and testing ssim 0.7762326300144196\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 58 Training loss 0.9750416517257691 training ssim 0.7791909098625183                   validation loss 1.0445546358823776 and testing ssim 0.7777468115091324\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 59 Training loss 0.9789405643939972 training ssim 0.7875766396522522                   validation loss 1.0451556295156479 and testing ssim 0.7848779559135437\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 60 Training loss 0.9715144246816635 training ssim 0.776704566180706                   validation loss 1.0597409158945084 and testing ssim 0.7777125537395477\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 61 Training loss 0.9858423292636871 training ssim 0.7740997821092606                   validation loss 1.0468385368585587 and testing ssim 0.7783507257699966\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 62 Training loss 0.9776054859161377 training ssim 0.7927838623523712                   validation loss 1.0436877757310867 and testing ssim 0.7918083369731903\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 63 Training loss 0.964952489733696 training ssim 0.7780293673276901                   validation loss 1.0477783977985382 and testing ssim 0.7863925695419312\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 64 Training loss 0.9645009249448776 training ssim 0.7849960863590241                   validation loss 1.039968341588974 and testing ssim 0.794946014881134\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 65 Training loss 0.9651389837265014 training ssim 0.7861317425966263                   validation loss 1.0671083480119705 and testing ssim 0.7849664688110352\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 66 Training loss 0.9625350087881088 training ssim 0.7893905490636826                   validation loss 1.036742627620697 and testing ssim 0.7840532064437866\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 67 Training loss 0.963455393910408 training ssim 0.7893094569444656                   validation loss 1.0227068066596985 and testing ssim 0.8104698061943054\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 68 Training loss 0.96253801882267 training ssim 0.7830044865608216                   validation loss 1.0503672808408737 and testing ssim 0.7835519909858704\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 69 Training loss 0.9511333495378494 training ssim 0.79012231528759                   validation loss 1.0324409455060959 and testing ssim 0.7896384000778198\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 70 Training loss 0.9522792249917984 training ssim 0.7896336257457733                   validation loss 1.0604014545679092 and testing ssim 0.7835197895765305\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 71 Training loss 0.9700534224510193 training ssim 0.7798276454210281                   validation loss 1.3669363260269165 and testing ssim 0.7611260414123535\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 72 Training loss 0.959714338183403 training ssim 0.7972992837429047                   validation loss 1.0373123437166214 and testing ssim 0.7912692576646805\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 73 Training loss 0.9480790376663208 training ssim 0.8028726935386657                   validation loss 1.0239606648683548 and testing ssim 0.8021978735923767\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 74 Training loss 0.9522075682878495 training ssim 0.7879140198230743                   validation loss 1.0520724207162857 and testing ssim 0.7838324755430222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 75 Training loss 0.9478057116270066 training ssim 0.7944766342639923                   validation loss 1.0474036931991577 and testing ssim 0.7910975813865662\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 76 Training loss 0.9370669186115265 training ssim 0.8007398009300232                   validation loss 1.0417663902044296 and testing ssim 0.7935532331466675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 77 Training loss 0.9299777507781982 training ssim 0.8069968074560165                   validation loss 1.0478710532188416 and testing ssim 0.7927135527133942\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 78 Training loss 0.9263198494911193 training ssim 0.8060123592615127                   validation loss 1.0264325588941574 and testing ssim 0.7921810448169708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 79 Training loss 0.9250706702470779 training ssim 0.8034879505634308                   validation loss 1.050310030579567 and testing ssim 0.7872921377420425\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 80 Training loss 0.9265681624412536 training ssim 0.8026610165834427                   validation loss 1.0507074296474457 and testing ssim 0.7997905164957047\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 81 Training loss 0.9178340315818787 training ssim 0.8040836244821549                   validation loss 1.0630341619253159 and testing ssim 0.7766464650630951\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 82 Training loss 0.9192750722169876 training ssim 0.808045893907547                   validation loss 1.024416670203209 and testing ssim 0.80573470890522\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 83 Training loss 0.9267154842615127 training ssim 0.8152830481529236                   validation loss 1.0550243854522705 and testing ssim 0.7676206678152084\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 84 Training loss 0.9222348302602768 training ssim 0.8088190108537674                   validation loss 1.0274419486522675 and testing ssim 0.8168249130249023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 85 Training loss 0.913319519162178 training ssim 0.8087352842092514                   validation loss 1.0554358959197998 and testing ssim 0.804019570350647\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 86 Training loss 0.916820815205574 training ssim 0.8187720984220505                   validation loss 1.0459522008895874 and testing ssim 0.8011460900306702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 87 Training loss 0.9196144223213196 training ssim 0.8041147321462632                   validation loss 1.0508027523756027 and testing ssim 0.7746463418006897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 88 Training loss 0.9069519937038422 training ssim 0.8172511458396912                   validation loss 1.0597654730081558 and testing ssim 0.7906403839588165\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 89 Training loss 0.9031507104635239 training ssim 0.8326280683279037                   validation loss 1.037788599729538 and testing ssim 0.8104951530694962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 90 Training loss 0.9042436242103576 training ssim 0.8345301538705826                   validation loss 1.0403077453374863 and testing ssim 0.8123388290405273\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 91 Training loss 0.9038197815418243 training ssim 0.8365994989871979                   validation loss 1.0617532581090927 and testing ssim 0.7980829924345016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 92 Training loss 0.9011973381042481 training ssim 0.8164414703845978                   validation loss 1.0273221284151077 and testing ssim 0.8296576738357544\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 93 Training loss 0.8967247068881988 training ssim 0.8255720525979996                   validation loss 1.055660456418991 and testing ssim 0.8044881522655487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 94 Training loss 0.8965058773756027 training ssim 0.8235080271959305                   validation loss 1.05428084731102 and testing ssim 0.8258208632469177\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 95 Training loss 0.9025818109512329 training ssim 0.8169566214084625                   validation loss 1.0616653710603714 and testing ssim 0.8006413280963898\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 96 Training loss 0.8906357824802399 training ssim 0.8175256818532943                   validation loss 1.0489806234836578 and testing ssim 0.786902979016304\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 97 Training loss 0.883830589056015 training ssim 0.8463575899600982                   validation loss 1.0550372004508972 and testing ssim 0.7920710146427155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 98 Training loss 0.8797564029693603 training ssim 0.8457097679376602                   validation loss 1.0283198803663254 and testing ssim 0.8170167207717896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 99 Training loss 0.8765823066234588 training ssim 0.8458906471729278                   validation loss 1.0381299257278442 and testing ssim 0.8051329255104065\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 100 Training loss 0.8687372386455536 training ssim 0.8513151973485946                   validation loss 1.036226287484169 and testing ssim 0.8171657770872116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 101 Training loss 0.8905632823705674 training ssim 0.8399171113967896                   validation loss 1.0506269037723541 and testing ssim 0.8293296098709106\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 102 Training loss 0.881531834602356 training ssim 0.840182614326477                   validation loss 1.0528165698051453 and testing ssim 0.8053630590438843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 103 Training loss 0.8698365360498428 training ssim 0.8537342011928558                   validation loss 1.0837272554636002 and testing ssim 0.785023644566536\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 104 Training loss 0.8696336925029755 training ssim 0.8383719831705093                   validation loss 1.0542470514774323 and testing ssim 0.8091877996921539\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 105 Training loss 0.8783351093530655 training ssim 0.8379177033901215                   validation loss 1.0432296097278595 and testing ssim 0.8148419111967087\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 106 Training loss 0.864135417342186 training ssim 0.8589327037334442                   validation loss 1.052507445216179 and testing ssim 0.7845029085874557\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 107 Training loss 0.8622951358556747 training ssim 0.8631356477737426                   validation loss 1.0540638267993927 and testing ssim 0.7971853464841843\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 108 Training loss 0.8594333201646804 training ssim 0.8485794097185135                   validation loss 1.0397167652845383 and testing ssim 0.8104302734136581\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 109 Training loss 0.8525546163320541 training ssim 0.8733916372060776                   validation loss 1.0551446229219437 and testing ssim 0.8156449049711227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 110 Training loss 0.8521657109260559 training ssim 0.8710141330957413                   validation loss 1.0476797968149185 and testing ssim 0.8263266831636429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 111 Training loss 0.8506101548671723 training ssim 0.8719092339277268                   validation loss 1.0406544357538223 and testing ssim 0.8282336294651031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 112 Training loss 0.8496529072523117 training ssim 0.8696690261363983                   validation loss 1.069090723991394 and testing ssim 0.7996511608362198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 113 Training loss 0.8543092966079712 training ssim 0.8622588723897934                   validation loss 1.0554173290729523 and testing ssim 0.8379955142736435\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 114 Training loss 0.8502145498991013 training ssim 0.8773834854364395                   validation loss 1.0826975405216217 and testing ssim 0.801777109503746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 115 Training loss 0.8548931241035461 training ssim 0.859439155459404                   validation loss 1.062055453658104 and testing ssim 0.7623914182186127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 116 Training loss 0.8559019356966019 training ssim 0.8697970151901245                   validation loss 1.0569432079792023 and testing ssim 0.7926112562417984\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 117 Training loss 0.8499120265245438 training ssim 0.8668019622564316                   validation loss 1.0528102219104767 and testing ssim 0.809014692902565\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 118 Training loss 0.8506716877222061 training ssim 0.862353402376175                   validation loss 1.0429550856351852 and testing ssim 0.8245053440332413\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 119 Training loss 0.8482022941112518 training ssim 0.8551481753587723                   validation loss 1.059553638100624 and testing ssim 0.8260542452335358\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 120 Training loss 0.8469665348529816 training ssim 0.8666222006082535                   validation loss 1.0685746669769287 and testing ssim 0.7932180017232895\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 121 Training loss 0.8420371830463409 training ssim 0.8707109063863754                   validation loss 1.0617423057556152 and testing ssim 0.8200789839029312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 122 Training loss 0.8298426777124405 training ssim 0.8841599106788636                   validation loss 1.04587122797966 and testing ssim 0.8056097626686096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 123 Training loss 0.8256663352251052 training ssim 0.8939970254898071                   validation loss 1.0814938992261887 and testing ssim 0.7708972245454788\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 124 Training loss 0.8299082726240158 training ssim 0.8736549556255341                   validation loss 1.0648940205574036 and testing ssim 0.8057031333446503\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 125 Training loss 0.8274473816156387 training ssim 0.8841261297464371                   validation loss 1.044918343424797 and testing ssim 0.799323558807373\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 126 Training loss 0.8114811450242996 training ssim 0.8994630187749862                   validation loss 1.0694393068552017 and testing ssim 0.8185148388147354\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 127 Training loss 0.8196357101202011 training ssim 0.8868715286254882                   validation loss 1.0826856195926666 and testing ssim 0.7914993911981583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 128 Training loss 0.8401118040084838 training ssim 0.8740385174751282                   validation loss 1.0775666385889053 and testing ssim 0.7850690484046936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 129 Training loss 0.8231202393770218 training ssim 0.8777266770601273                   validation loss 1.0469437837600708 and testing ssim 0.8336051404476166\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 130 Training loss 0.8142755836248398 training ssim 0.8958952456712723                   validation loss 1.0516958832740784 and testing ssim 0.842621698975563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 131 Training loss 0.8057126253843307 training ssim 0.903130567073822                   validation loss 1.0739901959896088 and testing ssim 0.8120866268873215\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 132 Training loss 0.8161009877920151 training ssim 0.8971784323453903                   validation loss 1.0440755039453506 and testing ssim 0.8219895362854004\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 133 Training loss 0.8030407905578614 training ssim 0.8979587078094482                   validation loss 1.0470684170722961 and testing ssim 0.8512097299098969\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 134 Training loss 0.821957528591156 training ssim 0.8878625631332397                   validation loss 1.0700221806764603 and testing ssim 0.818130150437355\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 135 Training loss 0.8086169302463532 training ssim 0.8844024986028671                   validation loss 1.0660374611616135 and testing ssim 0.8055970817804337\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 136 Training loss 0.8144708722829819 training ssim 0.8949866950511932                   validation loss 1.0390892028808594 and testing ssim 0.8117328584194183\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 137 Training loss 0.8204504698514938 training ssim 0.8905711621046066                   validation loss 1.0775524526834488 and testing ssim 0.83212611079216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 138 Training loss 0.8214338481426239 training ssim 0.8882893651723862                   validation loss 1.0845646113157272 and testing ssim 0.7883735448122025\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 139 Training loss 0.8416652232408524 training ssim 0.8802831530570984                   validation loss 1.0519486367702484 and testing ssim 0.8397935181856155\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 140 Training loss 0.8151935338973999 training ssim 0.8882047057151794                   validation loss 1.0793956071138382 and testing ssim 0.790742963552475\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 141 Training loss 0.8024989068508148 training ssim 0.8900864481925964                   validation loss 1.0696926414966583 and testing ssim 0.7966321557760239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 142 Training loss 0.7984781473875046 training ssim 0.9078350991010666                   validation loss 1.0552788376808167 and testing ssim 0.8337381035089493\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 143 Training loss 0.798633587360382 training ssim 0.8986248195171356                   validation loss 1.100672036409378 and testing ssim 0.7673743814229965\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 144 Training loss 0.8283546566963196 training ssim 0.8859350025653839                   validation loss 1.0808272510766983 and testing ssim 0.7895635664463043\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 145 Training loss 0.8169479429721832 training ssim 0.8909815043210983                   validation loss 1.0642035007476807 and testing ssim 0.8210746496915817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 146 Training loss 0.81228666305542 training ssim 0.8869517624378205                   validation loss 1.0634461492300034 and testing ssim 0.8197001218795776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 147 Training loss 0.8057270318269729 training ssim 0.8923817038536072                   validation loss 1.056553304195404 and testing ssim 0.8178658783435822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 148 Training loss 0.7993642508983612 training ssim 0.8976909399032593                   validation loss 1.0561651438474655 and testing ssim 0.8118723779916763\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 149 Training loss 0.7837628930807113 training ssim 0.911087903380394                   validation loss 1.0781760513782501 and testing ssim 0.8214195221662521\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 150 Training loss 0.7777375459671021 training ssim 0.9012534588575363                   validation loss 1.0564675033092499 and testing ssim 0.8293714076280594\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 151 Training loss 0.7846675127744674 training ssim 0.894701412320137                   validation loss 1.0492457151412964 and testing ssim 0.8004144579172134\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 152 Training loss 0.7758372485637665 training ssim 0.900033563375473                   validation loss 1.0748325884342194 and testing ssim 0.835992157459259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 153 Training loss 0.7813569992780686 training ssim 0.8990740478038788                   validation loss 1.0914339572191238 and testing ssim 0.8016581237316132\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 154 Training loss 0.7767795950174332 training ssim 0.9031191408634186                   validation loss 1.0364550054073334 and testing ssim 0.8474642783403397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 155 Training loss 0.7693574815988541 training ssim 0.9130641877651214                   validation loss 1.073006495833397 and testing ssim 0.83419468998909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 156 Training loss 0.7603759288787841 training ssim 0.9132221609354019                   validation loss 1.0721080303192139 and testing ssim 0.8046672493219376\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 157 Training loss 0.7682245790958404 training ssim 0.9085652381181717                   validation loss 1.0442667305469513 and testing ssim 0.8603491485118866\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 158 Training loss 0.7615471869707108 training ssim 0.913823202252388                   validation loss 1.072879582643509 and testing ssim 0.8176991790533066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 159 Training loss 0.7678443849086761 training ssim 0.9123111814260483                   validation loss 1.082528829574585 and testing ssim 0.8362067341804504\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 160 Training loss 0.7669891864061356 training ssim 0.900843259692192                   validation loss 1.065043568611145 and testing ssim 0.8047428876161575\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 161 Training loss 0.766919857263565 training ssim 0.8998339295387268                   validation loss 1.0601165294647217 and testing ssim 0.8443668335676193\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 162 Training loss 0.7685755282640457 training ssim 0.9021811664104462                   validation loss 1.0772400498390198 and testing ssim 0.8253232687711716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 163 Training loss 0.7643945217132568 training ssim 0.9055497229099274                   validation loss 1.081434115767479 and testing ssim 0.8124277144670486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 164 Training loss 0.7617721140384675 training ssim 0.9047408938407898                   validation loss 1.0469702035188675 and testing ssim 0.8500875234603882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 165 Training loss 0.7580419719219208 training ssim 0.9114048898220062                   validation loss 1.0769601315259933 and testing ssim 0.791326105594635\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 166 Training loss 0.7666589468717575 training ssim 0.9024623990058899                   validation loss 1.0639857947826385 and testing ssim 0.8096143454313278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 167 Training loss 0.7585518032312393 training ssim 0.9014070302248001                   validation loss 1.0863438844680786 and testing ssim 0.8025705963373184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 168 Training loss 0.7469827175140381 training ssim 0.908580732345581                   validation loss 1.0672540962696075 and testing ssim 0.8247095942497253\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 169 Training loss 0.7604068219661713 training ssim 0.8978270053863525                   validation loss 1.058988243341446 and testing ssim 0.8463151305913925\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 170 Training loss 0.7562592327594757 training ssim 0.9082670122385025                   validation loss 1.0764750689268112 and testing ssim 0.8096675872802734\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 171 Training loss 0.755333548784256 training ssim 0.9054522067308426                   validation loss 1.0697857737541199 and testing ssim 0.8312873989343643\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 172 Training loss 0.7572530031204223 training ssim 0.9026277989149094                   validation loss 1.0640593767166138 and testing ssim 0.8184970766305923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 173 Training loss 0.7556424170732499 training ssim 0.9065371155738831                   validation loss 1.0714047104120255 and testing ssim 0.8354151546955109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 174 Training loss 0.7522288084030151 training ssim 0.9113891959190369                   validation loss 1.0443513840436935 and testing ssim 0.8515604585409164\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 175 Training loss 0.7466533541679382 training ssim 0.9087737977504731                   validation loss 1.0748212188482285 and testing ssim 0.8209771364927292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 176 Training loss 0.7479082733392716 training ssim 0.9044914245605469                   validation loss 1.0765832364559174 and testing ssim 0.8116297125816345\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 177 Training loss 0.735610356926918 training ssim 0.9147713333368301                   validation loss 1.054465651512146 and testing ssim 0.8249840289354324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 178 Training loss 0.732350742816925 training ssim 0.9146332651376724                   validation loss 1.071655586361885 and testing ssim 0.8060432821512222\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 179 Training loss 0.7334363847970963 training ssim 0.9181264102458954                   validation loss 1.0901850759983063 and testing ssim 0.7921229302883148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 180 Training loss 0.7325356066226959 training ssim 0.9114102274179459                   validation loss 1.065349817276001 and testing ssim 0.796369656920433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 181 Training loss 0.7434478312730789 training ssim 0.9156366765499115                   validation loss 1.0572652518749237 and testing ssim 0.8239077031612396\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 182 Training loss 0.7344097644090652 training ssim 0.916786003112793                   validation loss 1.0908456295728683 and testing ssim 0.8074227422475815\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 183 Training loss 0.7261512368917465 training ssim 0.9189880132675171                   validation loss 1.074073612689972 and testing ssim 0.8161833435297012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 184 Training loss 0.7330306738615036 training ssim 0.9194701462984085                   validation loss 1.1135737001895905 and testing ssim 0.8023670464754105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 185 Training loss 0.7505022257566452 training ssim 0.9028931558132172                   validation loss 1.0629330575466156 and testing ssim 0.8357292264699936\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 186 Training loss 0.740485030412674 training ssim 0.9150345683097839                   validation loss 1.072357326745987 and testing ssim 0.8177518844604492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 187 Training loss 0.7395794749259949 training ssim 0.9012628465890884                   validation loss 1.0600294917821884 and testing ssim 0.8330083638429642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 188 Training loss 0.7280347049236298 training ssim 0.9094709575176239                   validation loss 1.0638937950134277 and testing ssim 0.8138517290353775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 189 Training loss 0.7292589724063874 training ssim 0.9116206020116806                   validation loss 1.095623418688774 and testing ssim 0.8132264316082001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 190 Training loss 0.7264000773429871 training ssim 0.912841659784317                   validation loss 1.07307069003582 and testing ssim 0.8409753143787384\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 191 Training loss 0.7220302224159241 training ssim 0.9144253253936767                   validation loss 1.0706513077020645 and testing ssim 0.8202494382858276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 192 Training loss 0.7225576728582382 training ssim 0.9106510221958161                   validation loss 1.0789504796266556 and testing ssim 0.8366131484508514\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 193 Training loss 0.7238555073738098 training ssim 0.9149638652801514                   validation loss 1.0852723121643066 and testing ssim 0.7823469191789627\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 194 Training loss 0.7319580972194671 training ssim 0.9076857060194016                   validation loss 1.0821575075387955 and testing ssim 0.8050051331520081\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 195 Training loss 0.729342570900917 training ssim 0.9157064735889435                   validation loss 1.0626217871904373 and testing ssim 0.8167917877435684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 196 Training loss 0.7164346396923065 training ssim 0.9121858686208725                   validation loss 1.0700147300958633 and testing ssim 0.8269602805376053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 197 Training loss 0.7036326885223388 training ssim 0.9210252910852432                   validation loss 1.0847523659467697 and testing ssim 0.8133951723575592\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 198 Training loss 0.7062155723571777 training ssim 0.9179105222225189                   validation loss 1.0924494415521622 and testing ssim 0.8298083990812302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 199 Training loss 0.7065188139677048 training ssim 0.9233733415603638                   validation loss 1.0737095326185226 and testing ssim 0.8538782447576523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 200 Training loss 0.7122554570436478 training ssim 0.917366361618042                   validation loss 1.083145871758461 and testing ssim 0.8119864165782928\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 201 Training loss 0.7199254870414734 training ssim 0.9172057032585144                   validation loss 1.0675890743732452 and testing ssim 0.8320306241512299\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 202 Training loss 0.7061030507087708 training ssim 0.9210275739431382                   validation loss 1.0986065715551376 and testing ssim 0.8028392046689987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 203 Training loss 0.7039105117321014 training ssim 0.9223186731338501                   validation loss 1.0828954875469208 and testing ssim 0.7930530905723572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 204 Training loss 0.7037721931934356 training ssim 0.9094355314970016                   validation loss 1.0736116170883179 and testing ssim 0.8349388390779495\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 205 Training loss 0.7049440652132034 training ssim 0.9188505440950394                   validation loss 1.0852294862270355 and testing ssim 0.8442819118499756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 206 Training loss 0.698120191693306 training ssim 0.9221797704696655                   validation loss 1.0758704096078873 and testing ssim 0.8007374554872513\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 207 Training loss 0.695334991812706 training ssim 0.9246848791837692                   validation loss 1.0865718126296997 and testing ssim 0.817298635840416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 208 Training loss 0.700432762503624 training ssim 0.9063706010580063                   validation loss 1.0832238644361496 and testing ssim 0.8188766241073608\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 209 Training loss 0.6973150670528412 training ssim 0.9138219863176346                   validation loss 1.0982381999492645 and testing ssim 0.8320164233446121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 210 Training loss 0.6919535130262375 training ssim 0.9207457363605499                   validation loss 1.1104305386543274 and testing ssim 0.8065046817064285\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 211 Training loss 0.6951767414808273 training ssim 0.9216338694095612                   validation loss 1.0848975032567978 and testing ssim 0.8219189196825027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 212 Training loss 0.6942459762096405 training ssim 0.9184574127197266                   validation loss 1.099196970462799 and testing ssim 0.8182899951934814\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 213 Training loss 0.6905813485383987 training ssim 0.9113857239484787                   validation loss 1.0943057090044022 and testing ssim 0.8017889261245728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 214 Training loss 0.6918759644031525 training ssim 0.9202936738729477                   validation loss 1.0848009586334229 and testing ssim 0.8200183212757111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 215 Training loss 0.6875440031290054 training ssim 0.9236726611852646                   validation loss 1.0969287753105164 and testing ssim 0.8237541168928146\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 216 Training loss 0.688856565952301 training ssim 0.923546114563942                   validation loss 1.0797608643770218 and testing ssim 0.8354188650846481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 217 Training loss 0.701139435172081 training ssim 0.9251807868480683                   validation loss 1.1053379625082016 and testing ssim 0.8059728145599365\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 218 Training loss 0.694205042719841 training ssim 0.9258793801069259                   validation loss 1.0947905480861664 and testing ssim 0.8236842006444931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 219 Training loss 0.6845388233661651 training ssim 0.9254597157239914                   validation loss 1.0949544608592987 and testing ssim 0.7934907972812653\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 220 Training loss 0.6900039672851562 training ssim 0.9120315700769425                   validation loss 1.1081765294075012 and testing ssim 0.8108165562152863\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 221 Training loss 0.6890671461820602 training ssim 0.9220550119876861                   validation loss 1.0889416635036469 and testing ssim 0.8418247848749161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 222 Training loss 0.6897544145584107 training ssim 0.9261146068572998                   validation loss 1.1142303347587585 and testing ssim 0.8142173290252686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 223 Training loss 0.6818335264921188 training ssim 0.9230496525764466                   validation loss 1.0823358595371246 and testing ssim 0.8448386192321777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 224 Training loss 0.6800207287073136 training ssim 0.9250642478466033                   validation loss 1.071043238043785 and testing ssim 0.8190895915031433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 225 Training loss 0.6846556067466736 training ssim 0.9142939358949661                   validation loss 1.0903379768133163 and testing ssim 0.8240869790315628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 226 Training loss 0.6880021691322327 training ssim 0.9184068381786347                   validation loss 1.1237104684114456 and testing ssim 0.7961075007915497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 227 Training loss 0.6798606425523758 training ssim 0.9238654255867005                   validation loss 1.0969126969575882 and testing ssim 0.8303237855434418\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 228 Training loss 0.6774129062891007 training ssim 0.9261964619159698                   validation loss 1.0826822370290756 and testing ssim 0.8247115761041641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 229 Training loss 0.6816816627979279 training ssim 0.9191010892391205                   validation loss 1.120171457529068 and testing ssim 0.8194284439086914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 230 Training loss 0.6801755458116532 training ssim 0.9244097322225571                   validation loss 1.0749262422323227 and testing ssim 0.8429301381111145\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 231 Training loss 0.6693875133991242 training ssim 0.9273367553949357                   validation loss 1.1106432378292084 and testing ssim 0.804288774728775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 232 Training loss 0.6696523934602737 training ssim 0.9265446245670319                   validation loss 1.0690000355243683 and testing ssim 0.8138538300991058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 233 Training loss 0.664174085855484 training ssim 0.9301486581563949                   validation loss 1.1046008914709091 and testing ssim 0.8212760537862778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 234 Training loss 0.6761964231729507 training ssim 0.9230863600969315                   validation loss 1.0783208459615707 and testing ssim 0.8384507894515991\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 235 Training loss 0.6638068407773972 training ssim 0.9264404654502869                   validation loss 1.079867199063301 and testing ssim 0.8148009330034256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 236 Training loss 0.6640184164047241 training ssim 0.9256968080997467                   validation loss 1.0702351033687592 and testing ssim 0.8487158417701721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 237 Training loss 0.6692107349634171 training ssim 0.9245168775320053                   validation loss 1.098985642194748 and testing ssim 0.8072496056556702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 238 Training loss 0.6751111537218094 training ssim 0.9218213528394699                   validation loss 1.0992354154586792 and testing ssim 0.8104735612869263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 239 Training loss 0.6665235817432403 training ssim 0.9229234784841538                   validation loss 1.1112260073423386 and testing ssim 0.8163036704063416\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 240 Training loss 0.6714212387800217 training ssim 0.9224013775587082                   validation loss 1.0810243636369705 and testing ssim 0.8323074281215668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 241 Training loss 0.9078387796878815 training ssim 0.8911328703165055                   validation loss 1.124673768877983 and testing ssim 0.7852078974246979\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 242 Training loss 0.8625150084495544 training ssim 0.8786968290805817                   validation loss 1.0771958529949188 and testing ssim 0.8626054525375366\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 243 Training loss 0.7974237978458405 training ssim 0.903745025396347                   validation loss 1.1068528443574905 and testing ssim 0.7749000042676926\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 244 Training loss 0.7646836996078491 training ssim 0.9096222937107086                   validation loss 1.076784461736679 and testing ssim 0.827329233288765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 245 Training loss 0.7453606754541398 training ssim 0.9116648405790329                   validation loss 1.0769326388835907 and testing ssim 0.8394222557544708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 246 Training loss 0.7252092301845551 training ssim 0.9163733869791031                   validation loss 1.0811488628387451 and testing ssim 0.8174024820327759\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 247 Training loss 0.7154496341943741 training ssim 0.9145743548870087                   validation loss 1.0701791197061539 and testing ssim 0.848499521613121\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 248 Training loss 0.7057762563228607 training ssim 0.927965846657753                   validation loss 1.0951498746871948 and testing ssim 0.8254772424697876\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 249 Training loss 0.6898654729127884 training ssim 0.9240385919809342                   validation loss 1.0904996991157532 and testing ssim 0.8035148829221725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 250 Training loss 0.6765932112932205 training ssim 0.9283844143152237                   validation loss 1.0975438952445984 and testing ssim 0.8316791206598282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 251 Training loss 0.6770195156335831 training ssim 0.9293276548385621                   validation loss 1.1175758689641953 and testing ssim 0.8042172491550446\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 252 Training loss 0.6753329753875732 training ssim 0.9251476764678955                   validation loss 1.0995504558086395 and testing ssim 0.8357587903738022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 253 Training loss 0.6809613853693008 training ssim 0.9216164469718933                   validation loss 1.0975175201892853 and testing ssim 0.8392353951931\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 254 Training loss 0.6987952083349228 training ssim 0.9230734318494797                   validation loss 1.1105323284864426 and testing ssim 0.8497666269540787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 255 Training loss 0.6859331250190734 training ssim 0.9210167020559311                   validation loss 1.1006188839673996 and testing ssim 0.82724329829216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 256 Training loss 0.6872190266847611 training ssim 0.9091154426336289                   validation loss 1.097797304391861 and testing ssim 0.7979958653450012\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 257 Training loss 0.6943718522787095 training ssim 0.9200086414813995                   validation loss 1.069560557603836 and testing ssim 0.8607102632522583\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 258 Training loss 0.6788855880498886 training ssim 0.9244137734174729                   validation loss 1.083464965224266 and testing ssim 0.854925125837326\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 259 Training loss 0.679954132437706 training ssim 0.9166804730892182                   validation loss 1.0946500897407532 and testing ssim 0.8511499017477036\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 260 Training loss 0.6675531089305877 training ssim 0.9248485743999482                   validation loss 1.0899207592010498 and testing ssim 0.8432522267103195\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 261 Training loss 0.6664564281702041 training ssim 0.9285947382450104                   validation loss 1.0867693424224854 and testing ssim 0.8298446238040924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 262 Training loss 0.6700646698474884 training ssim 0.9150177001953125                   validation loss 1.1078932136297226 and testing ssim 0.8146800696849823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 263 Training loss 0.6698561996221543 training ssim 0.9196755677461624                   validation loss 1.090749353170395 and testing ssim 0.8395867943763733\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 264 Training loss 0.661785465478897 training ssim 0.9288158029317856                   validation loss 1.0940962433815002 and testing ssim 0.8183540850877762\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 265 Training loss 0.6588569313287735 training ssim 0.9285908192396164                   validation loss 1.554653525352478 and testing ssim 0.7032066136598587\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 266 Training loss 0.7141103982925415 training ssim 0.9245343267917633                   validation loss 1.0864173769950867 and testing ssim 0.8234645128250122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 267 Training loss 0.6946021735668182 training ssim 0.9223420798778534                   validation loss 1.086855709552765 and testing ssim 0.840061292052269\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 268 Training loss 0.6908894747495651 training ssim 0.9192891836166381                   validation loss 1.126156985759735 and testing ssim 0.8004058301448822\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 269 Training loss 0.6787788391113281 training ssim 0.9177453517913818                   validation loss 1.078434705734253 and testing ssim 0.8532187342643738\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 270 Training loss 0.6759241908788681 training ssim 0.9129606902599334                   validation loss 1.08835007250309 and testing ssim 0.8192576766014099\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 271 Training loss 0.6787301659584045 training ssim 0.8968660533428192                   validation loss 1.0867290198802948 and testing ssim 0.8530854284763336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 272 Training loss 0.6657248944044113 training ssim 0.9146236449480056                   validation loss 1.0883810073137283 and testing ssim 0.8404510319232941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 273 Training loss 0.6567449152469635 training ssim 0.9209699839353561                   validation loss 1.0911835581064224 and testing ssim 0.8290483802556992\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 274 Training loss 0.6580908030271531 training ssim 0.9260474175214768                   validation loss 1.0882186740636826 and testing ssim 0.8668309301137924\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 275 Training loss 0.6668400853872299 training ssim 0.9143430948257446                   validation loss 1.1189489960670471 and testing ssim 0.8126301169395447\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 276 Training loss 0.6542837202548981 training ssim 0.9267053425312042                   validation loss 1.0895859003067017 and testing ssim 0.8328033089637756\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 277 Training loss 0.6522480815649032 training ssim 0.9199174404144287                   validation loss 1.1030981838703156 and testing ssim 0.8001182526350021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 278 Training loss 0.6623547524213791 training ssim 0.9110434651374817                   validation loss 1.1166354268789291 and testing ssim 0.8308999538421631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 279 Training loss 0.6550461769104003 training ssim 0.9211688071489335                   validation loss 1.0993762761354446 and testing ssim 0.8128832876682281\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 280 Training loss 0.6429535865783691 training ssim 0.928167924284935                   validation loss 1.1188376992940903 and testing ssim 0.8214908540248871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 281 Training loss 0.6385915517807007 training ssim 0.932819026708603                   validation loss 1.1086611300706863 and testing ssim 0.8297571092844009\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 282 Training loss 0.6367759555578232 training ssim 0.9311687290668488                   validation loss 1.080940142273903 and testing ssim 0.8357486426830292\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 283 Training loss 0.6354647219181061 training ssim 0.9330672651529313                   validation loss 1.1121856421232224 and testing ssim 0.8223244249820709\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 284 Training loss 0.6317323207855224 training ssim 0.9334079504013062                   validation loss 1.0733736902475357 and testing ssim 0.8730146139860153\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 285 Training loss 0.6270331650972366 training ssim 0.9303497612476349                   validation loss 1.0972526520490646 and testing ssim 0.8486307859420776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 286 Training loss 0.6369260147213935 training ssim 0.9224367320537568                   validation loss 1.1082286536693573 and testing ssim 0.7967104911804199\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 287 Training loss 0.6305582597851753 training ssim 0.9344649285078048                   validation loss 1.109962522983551 and testing ssim 0.8319383412599564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 288 Training loss 0.6297103554010391 training ssim 0.9311218649148941                   validation loss 1.088993951678276 and testing ssim 0.8298372030258179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 289 Training loss 0.6218549877405166 training ssim 0.9352414160966873                   validation loss 1.1123326569795609 and testing ssim 0.843334749341011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 290 Training loss 0.6258935898542404 training ssim 0.9359419167041778                   validation loss 1.0944441109895706 and testing ssim 0.8583157062530518\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 291 Training loss 0.6319544658064842 training ssim 0.9347416073083877                   validation loss 1.1095623075962067 and testing ssim 0.8306079208850861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 292 Training loss 0.6300358206033707 training ssim 0.9292853832244873                   validation loss 1.1166000664234161 and testing ssim 0.856255054473877\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 293 Training loss 0.620280598104 training ssim 0.9304264307022094                   validation loss 1.1175422370433807 and testing ssim 0.8318015933036804\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 294 Training loss 0.6194194033741951 training ssim 0.9375895440578461                   validation loss 1.112734615802765 and testing ssim 0.8375430107116699\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 295 Training loss 0.621133203804493 training ssim 0.9341767430305481                   validation loss 1.1311317831277847 and testing ssim 0.8153075128793716\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 296 Training loss 0.6203969776630401 training ssim 0.9342949956655502                   validation loss 1.104928269982338 and testing ssim 0.8308022767305374\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 297 Training loss 0.6177755743265152 training ssim 0.9359177201986313                   validation loss 1.1090075820684433 and testing ssim 0.8262462913990021\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 298 Training loss 0.6268316298723221 training ssim 0.9238934218883514                   validation loss 1.1046388149261475 and testing ssim 0.8631631433963776\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 299 Training loss 0.6251480370759964 training ssim 0.9302386671304703                   validation loss 1.115715116262436 and testing ssim 0.831400066614151\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 300 Training loss 0.6166168242692948 training ssim 0.9361343681812286                   validation loss 1.0984267890453339 and testing ssim 0.849561870098114\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 301 Training loss 0.6158501029014587 training ssim 0.9359020382165909                   validation loss 1.085206538438797 and testing ssim 0.8590205907821655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 302 Training loss 0.6206237226724625 training ssim 0.9300024747848511                   validation loss 1.116143986582756 and testing ssim 0.8167577385902405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 303 Training loss 0.6270070433616638 training ssim 0.9198221236467361                   validation loss 1.1028793454170227 and testing ssim 0.8289539366960526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 304 Training loss 0.6140342622995376 training ssim 0.9354101836681366                   validation loss 1.1312566101551056 and testing ssim 0.801229864358902\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 305 Training loss 0.6189870834350586 training ssim 0.9282739251852036                   validation loss 1.1157660782337189 and testing ssim 0.8246360421180725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 306 Training loss 0.6263491988182068 training ssim 0.9269466370344162                   validation loss 1.1301326751708984 and testing ssim 0.7953210920095444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 307 Training loss 0.6136038169264794 training ssim 0.9340661883354187                   validation loss 1.1080314666032791 and testing ssim 0.8456804007291794\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 308 Training loss 0.6075245648622513 training ssim 0.9356555253267288                   validation loss 1.1050659716129303 and testing ssim 0.8323803693056107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 309 Training loss 0.6142836511135101 training ssim 0.9341052770614624                   validation loss 1.1088150143623352 and testing ssim 0.828762024641037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 310 Training loss 0.6066087424755097 training ssim 0.9349032789468765                   validation loss 1.1272228956222534 and testing ssim 0.8254432678222656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 311 Training loss 0.6167244866490365 training ssim 0.9329133242368698                   validation loss 1.1209169626235962 and testing ssim 0.8487079292535782\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 312 Training loss 0.606507882475853 training ssim 0.9376583218574523                   validation loss 1.1260384321212769 and testing ssim 0.829476848244667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 313 Training loss 0.6071874737739563 training ssim 0.9376290619373322                   validation loss 1.1091111898422241 and testing ssim 0.8233022689819336\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 314 Training loss 0.6061607480049134 training ssim 0.9350735932588577                   validation loss 1.1438507735729218 and testing ssim 0.8075765073299408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 315 Training loss 0.6164468735456466 training ssim 0.9233395278453826                   validation loss 1.1485756188631058 and testing ssim 0.8124977946281433\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 316 Training loss 0.6220778882503509 training ssim 0.928567060828209                   validation loss 1.1069419384002686 and testing ssim 0.7979480624198914\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 317 Training loss 0.613784809410572 training ssim 0.933340871334076                   validation loss 1.13107630610466 and testing ssim 0.8099908232688904\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 318 Training loss 0.5995880454778671 training ssim 0.9372509717941284                   validation loss 1.1098878234624863 and testing ssim 0.8411793559789658\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 319 Training loss 0.5903942450881005 training ssim 0.9395918488502503                   validation loss 1.1150034368038177 and testing ssim 0.8191445767879486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 320 Training loss 0.5979057803750039 training ssim 0.9358079433441162                   validation loss 1.1132595390081406 and testing ssim 0.8248948752880096\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 321 Training loss 0.6017676264047622 training ssim 0.9316259175539017                   validation loss 1.0999070703983307 and testing ssim 0.8214289993047714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 322 Training loss 0.5997819051146507 training ssim 0.9344250917434692                   validation loss 1.1242082715034485 and testing ssim 0.7888972461223602\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 323 Training loss 0.5961012035608292 training ssim 0.9392620921134949                   validation loss 1.120471253991127 and testing ssim 0.8275785893201828\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 324 Training loss 0.5979652047157288 training ssim 0.935774278640747                   validation loss 1.1362919509410858 and testing ssim 0.8085508495569229\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 325 Training loss 0.600896367430687 training ssim 0.9328568667173386                   validation loss 1.1275876760482788 and testing ssim 0.7968063056468964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 326 Training loss 0.6166494160890579 training ssim 0.9352634727954865                   validation loss 1.1332228481769562 and testing ssim 0.8127736896276474\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 327 Training loss 0.6041417837142944 training ssim 0.9266419231891632                   validation loss 1.1301604509353638 and testing ssim 0.8049017786979675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 328 Training loss 0.6002832919359207 training ssim 0.9364416033029557                   validation loss 1.097369983792305 and testing ssim 0.8213995695114136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 329 Training loss 0.6014121502637864 training ssim 0.9371449291706085                   validation loss 1.1159323006868362 and testing ssim 0.855065181851387\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 330 Training loss 0.5945453345775604 training ssim 0.9385662138462066                   validation loss 1.1501409113407135 and testing ssim 0.8000632375478745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 331 Training loss 0.5963610053062439 training ssim 0.9370821416378021                   validation loss 1.132599264383316 and testing ssim 0.810798317193985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 332 Training loss 0.5932204723358154 training ssim 0.9352572947740555                   validation loss 1.1156370788812637 and testing ssim 0.8338278979063034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 333 Training loss 0.5974765345454216 training ssim 0.9309534698724746                   validation loss 1.099141001701355 and testing ssim 0.8572890907526016\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 334 Training loss 0.6070978224277497 training ssim 0.9356673330068588                   validation loss 1.10844187438488 and testing ssim 0.8305013328790665\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 335 Training loss 0.5999428033828735 training ssim 0.9316416382789612                   validation loss 1.102212354540825 and testing ssim 0.8349084109067917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 336 Training loss 0.5975811064243317 training ssim 0.9312613993883133                   validation loss 1.117397591471672 and testing ssim 0.7799762934446335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 337 Training loss 0.5928241893649101 training ssim 0.9299969673156738                   validation loss 1.1220416575670242 and testing ssim 0.8128973990678787\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 338 Training loss 0.5856734603643418 training ssim 0.9360339492559433                   validation loss 1.1082754135131836 and testing ssim 0.8338409215211868\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 339 Training loss 0.583986496925354 training ssim 0.9388907074928283                   validation loss 1.1191405355930328 and testing ssim 0.8211429566144943\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 340 Training loss 0.576924067735672 training ssim 0.9382431596517563                   validation loss 1.1229660362005234 and testing ssim 0.8534950315952301\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 341 Training loss 0.5817352861166001 training ssim 0.9352776229381561                   validation loss 1.1128276586532593 and testing ssim 0.8282554149627686\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 342 Training loss 0.575988994538784 training ssim 0.9382411062717437                   validation loss 1.1475226432085037 and testing ssim 0.8097427934408188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 343 Training loss 0.587828466296196 training ssim 0.9388988256454468                   validation loss 1.1234072297811508 and testing ssim 0.8127113431692123\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 344 Training loss 0.5914453655481339 training ssim 0.9342503309249878                   validation loss 1.1359187066555023 and testing ssim 0.8239192962646484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 345 Training loss 0.5902914375066757 training ssim 0.931638166308403                   validation loss 1.115745097398758 and testing ssim 0.8309360444545746\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 346 Training loss 0.5924521416425705 training ssim 0.9361234843730927                   validation loss 1.1028978526592255 and testing ssim 0.8546438217163086\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 347 Training loss 0.5906731888651848 training ssim 0.93899664580822                   validation loss 1.1251881569623947 and testing ssim 0.8290150314569473\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 348 Training loss 0.5776745393872261 training ssim 0.9387545824050904                   validation loss 1.118708610534668 and testing ssim 0.8212758153676987\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 349 Training loss 0.5743974521756172 training ssim 0.9381079018115998                   validation loss 1.1486385613679886 and testing ssim 0.8068218976259232\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 350 Training loss 0.5788781389594078 training ssim 0.9362954050302505                   validation loss 1.1226370632648468 and testing ssim 0.8441356420516968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 351 Training loss 0.5676034659147262 training ssim 0.9416432559490204                   validation loss 1.1332580596208572 and testing ssim 0.8296453207731247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 352 Training loss 0.5688847184181214 training ssim 0.9398533076047897                   validation loss 1.1217752993106842 and testing ssim 0.8229851871728897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 353 Training loss 0.5662450835108757 training ssim 0.9420399129390716                   validation loss 1.1283853352069855 and testing ssim 0.8064091503620148\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 354 Training loss 0.5848276510834693 training ssim 0.9312535226345062                   validation loss 1.1079043000936508 and testing ssim 0.7794155031442642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 355 Training loss 0.592769518494606 training ssim 0.9276467710733414                   validation loss 1.112981140613556 and testing ssim 0.8310865461826324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 356 Training loss 0.5830168128013611 training ssim 0.9359326601028443                   validation loss 1.1337458938360214 and testing ssim 0.8157224655151367\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 357 Training loss 0.5833982318639755 training ssim 0.938477286696434                   validation loss 1.129248172044754 and testing ssim 0.8142094761133194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 358 Training loss 0.5804592534899712 training ssim 0.9345208168029785                   validation loss 1.1312293410301208 and testing ssim 0.8187510669231415\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 359 Training loss 0.5753721699118615 training ssim 0.9370626002550125                   validation loss 1.1210822612047195 and testing ssim 0.8246636837720871\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 360 Training loss 0.5698661804199219 training ssim 0.9392577320337295                   validation loss 1.114754557609558 and testing ssim 0.843948245048523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 361 Training loss 0.5749710544943809 training ssim 0.9309205889701844                   validation loss 1.1054429709911346 and testing ssim 0.8261839300394058\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 362 Training loss 0.5760280877351761 training ssim 0.9362845540046691                   validation loss 1.1376065909862518 and testing ssim 0.8152167052030563\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 363 Training loss 0.5697591096162796 training ssim 0.9415830940008163                   validation loss 1.1129893362522125 and testing ssim 0.8171585649251938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 364 Training loss 0.5649112686514854 training ssim 0.9391853868961334                   validation loss 1.1479545533657074 and testing ssim 0.8137385547161102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 365 Training loss 0.5636563867330551 training ssim 0.9384874135255814                   validation loss 1.1312463581562042 and testing ssim 0.8148994296789169\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 366 Training loss 0.5608277425169945 training ssim 0.943073108792305                   validation loss 1.1301136910915375 and testing ssim 0.8372531831264496\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 367 Training loss 0.5623421385884285 training ssim 0.9379552572965622                   validation loss 1.1235214173793793 and testing ssim 0.8420208245515823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 368 Training loss 0.555912172794342 training ssim 0.9415731966495514                   validation loss 1.1389634907245636 and testing ssim 0.8155191838741302\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 369 Training loss 0.5631578877568245 training ssim 0.9371956914663315                   validation loss 1.1109841912984848 and testing ssim 0.8488182425498962\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 370 Training loss 0.565762035548687 training ssim 0.9349187433719635                   validation loss 1.1485570818185806 and testing ssim 0.808615118265152\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 371 Training loss 0.5629451990127563 training ssim 0.9383224457502365                   validation loss 1.1266300231218338 and testing ssim 0.8202256709337234\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 372 Training loss 0.5610274016857147 training ssim 0.9394757926464081                   validation loss 1.1096087545156479 and testing ssim 0.8401591926813126\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 373 Training loss 0.565078404545784 training ssim 0.9375389009714127                   validation loss 1.1398947536945343 and testing ssim 0.8103731423616409\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 374 Training loss 0.5826945766806603 training ssim 0.9376170724630356                   validation loss 1.133265197277069 and testing ssim 0.8202438056468964\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 375 Training loss 0.5721556261181832 training ssim 0.9422380566596985                   validation loss 1.1438414752483368 and testing ssim 0.8163631707429886\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 376 Training loss 0.5622643917798996 training ssim 0.9433212012052536                   validation loss 1.116903007030487 and testing ssim 0.8590717911720276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 377 Training loss 0.564234521985054 training ssim 0.9386847496032715                   validation loss 1.1221382021903992 and testing ssim 0.8178461045026779\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 378 Training loss 0.5681504115462304 training ssim 0.9292662173509598                   validation loss 1.1191918104887009 and testing ssim 0.8022549003362656\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 379 Training loss 0.5828523576259613 training ssim 0.932789146900177                   validation loss 1.1075952351093292 and testing ssim 0.8591148555278778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 380 Training loss 0.5738885700702667 training ssim 0.9310220003128051                   validation loss 1.1251067966222763 and testing ssim 0.8300438076257706\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 381 Training loss 0.5737937539815903 training ssim 0.9374183654785156                   validation loss 1.1322120428085327 and testing ssim 0.8234218508005142\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 382 Training loss 0.5729344248771667 training ssim 0.9313055485486984                   validation loss 1.1295980215072632 and testing ssim 0.793599009513855\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 383 Training loss 0.5654311388731003 training ssim 0.934041154384613                   validation loss 1.1191683262586594 and testing ssim 0.8103542476892471\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 384 Training loss 0.5700298801064492 training ssim 0.9322994619607925                   validation loss 1.1412123441696167 and testing ssim 0.8281345069408417\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 385 Training loss 0.5598928228020668 training ssim 0.9364618629217147                   validation loss 1.1235435903072357 and testing ssim 0.8216484040021896\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 386 Training loss 0.5652369230985641 training ssim 0.9394435673952103                   validation loss 1.1123984903097153 and testing ssim 0.816504642367363\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 387 Training loss 0.5592806339263916 training ssim 0.9374782025814057                   validation loss 1.133900448679924 and testing ssim 0.8132513165473938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 388 Training loss 0.5621167078614235 training ssim 0.9393824994564056                   validation loss 1.1294159293174744 and testing ssim 0.8233877569437027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 389 Training loss 0.5628110200166703 training ssim 0.9371384233236313                   validation loss 1.1157684922218323 and testing ssim 0.8175741136074066\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 390 Training loss 0.5553189620375634 training ssim 0.9408942550420761                   validation loss 1.1328473836183548 and testing ssim 0.8078532516956329\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 391 Training loss 0.5564423412084579 training ssim 0.9381423175334931                   validation loss 1.1221065074205399 and testing ssim 0.8302309215068817\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 392 Training loss 0.5531243562698365 training ssim 0.944642773270607                   validation loss 1.1412818431854248 and testing ssim 0.795908585190773\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 393 Training loss 0.5573384925723076 training ssim 0.9340135872364044                   validation loss 1.1044131070375443 and testing ssim 0.8449310213327408\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 394 Training loss 0.5529405638575554 training ssim 0.94079769551754                   validation loss 1.1449878513813019 and testing ssim 0.8323353976011276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 395 Training loss 0.5508324980735779 training ssim 0.9359204679727554                   validation loss 1.138862431049347 and testing ssim 0.8288658410310745\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 396 Training loss 0.5474095046520233 training ssim 0.9384572505950928                   validation loss 1.115369513630867 and testing ssim 0.8555767387151718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 397 Training loss 0.5484139129519463 training ssim 0.9398613303899765                   validation loss 1.1229074448347092 and testing ssim 0.8325427025556564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 398 Training loss 0.5514286965131759 training ssim 0.9420609623193741                   validation loss 1.1175900548696518 and testing ssim 0.8161426335573196\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 399 Training loss 0.5506131798028946 training ssim 0.940800404548645                   validation loss 1.1400909721851349 and testing ssim 0.8009461462497711\n"
          ]
        }
      ],
      "source": [
        "import os \n",
        "import sys \n",
        "import math \n",
        "import copy \n",
        "\n",
        "import numpy as np \n",
        "\n",
        "import torch \n",
        "import torch.nn as nn  \n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "#from dataset import BrainTumorDataset \n",
        "#from encoder.encoder_model import get_preprocessing_fn \n",
        "#from Model import UNeT \n",
        "#from model_training import train, evaluate  \n",
        "#from utils import save_figure \n",
        "\n",
        "\n",
        "def main(model, preprocessing, device, width, height, learning_rate, weight_decay,  batch_size=4, num_epochs=10):\n",
        "    train_dataset  = BrainTumorDataset(preprocessing_fun=preprocessing, image_size=(height, width)) \n",
        "    valida_dataset = BrainTumorDataset(train=False, preprocessing_fun=preprocessing, image_size=(height, width)) \n",
        "    print(len(train_dataset), len(valida_dataset))\n",
        "\n",
        "\n",
        "    train_loader  = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader   = data.DataLoader(valida_dataset, batch_size=batch_size, shuffle=False)\n",
        "    print(len(train_loader), len(test_loader))\n",
        "\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "    \n",
        "    best_model_loss = 1e10 \n",
        "    best_model_wts  = copy.deepcopy(model.state_dict())  \n",
        "    best_ssimScore = -1 \n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model, training_losss, train_ssim = train(model, train_loader, optimizer, device) \n",
        "        model, val_losses, test_ssim = evaluate(model, test_loader, device) \n",
        "\n",
        "        print(f'epoch {epoch} Training loss {training_losss} training ssim {train_ssim} \\\n",
        "                  validation loss {val_losses} and testing ssim {test_ssim}')\n",
        "\n",
        "        if best_model_loss  > val_losses: \n",
        "            best_model_loss = val_losses \n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            best_ssimScore = test_ssim\n",
        "\n",
        "        if epoch %50 ==0 :\n",
        "            learning_rate = learning_rate /10\n",
        "\n",
        "        save_figure(model, test_loader, epoch, device) \n",
        "\n",
        "    # print(f'Best validation loss {best_model_loss} and best ssim score {best_ssimScore}')\n",
        "    # torch.save(best_model_wts.state_dict(), 'model_weights.pth')\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    width = 640\n",
        "    height = 640\n",
        "    encoder_name= 'resnet18' \n",
        "    learning_rate = 5e-4 \n",
        "    weight_decay = 1e-5 \n",
        "    batch_size = 4 \n",
        "\n",
        "    model = UNeT(encoder_name=encoder_name)\n",
        "    model = model.to(device)\n",
        "    preprocessing =  get_preprocessing_fn(encoder_name=encoder_name, pretrained='ssl')\n",
        "\n",
        "    main(model, preprocessing=preprocessing, device=device, width=width, height=height, \n",
        "                       learning_rate=learning_rate, weight_decay=weight_decay, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gp4dviY7X_-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59938726-1420-447b-d7e5-af5f09699785"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "79 13\n",
            "20 4\n"
          ]
        }
      ],
      "source": [
        "train_dataset  = BrainTumorDataset(preprocessing_fun=preprocessing, image_size=(height, width)) \n",
        "valida_dataset = BrainTumorDataset(train=False, preprocessing_fun=preprocessing, image_size=(height, width)) \n",
        "print(len(train_dataset), len(valida_dataset))\n",
        "\n",
        "\n",
        "train_loader  = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader   = data.DataLoader(valida_dataset, batch_size=batch_size, shuffle=False)\n",
        "print(len(train_loader), len(test_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCAPzU3-x_wD"
      },
      "outputs": [],
      "source": [
        "def save_figure1(loader, num_epochs, device, mean = [0.485, 0.456, 0.406], std= [0.229, 0.224, 0.225]):\n",
        "    #model.eval() \n",
        "\n",
        "    if not os.path.exists(os.path.join(os.getcwd(), 'save_results1')):\n",
        "        os.mkdir(os.path.join(os.getcwd(), 'save_results1')) \n",
        "\n",
        "    result_dir = os.path.join(os.getcwd(), 'save_results1')\n",
        "    if not os.path.exists(os.path.join(result_dir, str(num_epoch))):\n",
        "        os.mkdir(os.path.join(result_dir, str(num_epoch))) \n",
        "\n",
        "    save_dir = os.path.join(result_dir, str(num_epoch))\n",
        "    for idx, (x, y) in enumerate(loader):\n",
        "        x = x.to(device).float()  \n",
        "        with torch.no_grad():\n",
        "            #out = torch.sigmoid(model(x))  \n",
        "            #torchvision.utils.save_image(out[2,:], f\"{save_dir}/pred_{idx}.png\") \n",
        "            torchvision.utils.save_image(y[3,:],  f\"{save_dir}/target_{idx}.png\")\n",
        "            x = x.permute(0, 2, 3, 1).cpu().numpy() \n",
        "            x = (x *np.array(std)) + np.array(mean) \n",
        "            x = x / x.max() \n",
        "            x = np.transpose(x, (0, 3, 1, 2)) \n",
        "            x = torch.from_numpy(x).float().to(device)\n",
        "            torchvision.utils.save_image(x[3,:], f\"{save_dir}/pnoisy_{idx}.png\")\n",
        "        break "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4UouRWiXwBL"
      },
      "outputs": [],
      "source": [
        "num_epoch =10\n",
        "save_figure1(test_loader, num_epoch, device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bbce8d8da68b472cac9f34ec6ad3eb21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9470d6de3fbc4e92bd0f32ca21a97980",
              "IPY_MODEL_f260706213e64beeb338ce2f777023f4",
              "IPY_MODEL_9657c93b8c724add96ed41ce1c6c5ae4"
            ],
            "layout": "IPY_MODEL_e6f1c28fbeb54dfdb9d05bd837d8a343"
          }
        },
        "9470d6de3fbc4e92bd0f32ca21a97980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_141e3b4795194e04980e86e292750e7b",
            "placeholder": "​",
            "style": "IPY_MODEL_e048570862be41cc9aa293811a958da4",
            "value": "100%"
          }
        },
        "f260706213e64beeb338ce2f777023f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a34277f83ad545cb876d7d9b2ec9f3fe",
            "max": 553433881,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1e2d696f1f8f40f8b9d7ebfcd5d99587",
            "value": 553433881
          }
        },
        "9657c93b8c724add96ed41ce1c6c5ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40c5185dd0f04d7d907d731e1446d492",
            "placeholder": "​",
            "style": "IPY_MODEL_d6e7d301ffc74f4f88df86d07525d317",
            "value": " 528M/528M [00:02&lt;00:00, 207MB/s]"
          }
        },
        "e6f1c28fbeb54dfdb9d05bd837d8a343": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "141e3b4795194e04980e86e292750e7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e048570862be41cc9aa293811a958da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a34277f83ad545cb876d7d9b2ec9f3fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e2d696f1f8f40f8b9d7ebfcd5d99587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "40c5185dd0f04d7d907d731e1446d492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6e7d301ffc74f4f88df86d07525d317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}